# Fashion mnist autoencoder

## Introduction

Autoencoder is a deep learning model which consists of two parts: encoder and decoder. The role of the encoder is to compress high dimensional data into low dimensional representation. Then decoder tries to recreate the original data from the encoded one.
Autoencoders architecture is widely used in the following problems:

* Dimensionality reduction
* Noise reduction
* Generative models
* Data augmentation

To learn more about autoencoders visit [an article about autoencoders](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798 "an article about autoencoders") and [Wikipedia](https://en.wikipedia.org/wiki/Autoencoder "Wikipedia") .

As we have a basic knowledge about autoencoders we might dive into implementation.

## Imports

At the very beginning, we have to import essential packages. ```Axon``` will be the primary tool to build a deep learning model. Apart from that, we need to import ```EXLA``` to accelerate calculations, ```Nx``` since it gives us useful functions like ```Nx.to_heatmap``` and tensor operations, and finally ```Scidata``` to download training data.

```elixir
Mix.install([
  {:axon, "~> 0.1.0-dev", github: "elixir-nx/axon"},
  {:exla, github: "elixir-nx/exla", sparse: "exla"},
  {:nx, "~> 0.1.0-dev", github: "elixir-nx/nx", sparse: "nx", override: true},
  {:scidata, "~> 0.1.3"}
])
```

## Configure platforms precedence

Configure default platform with accelerator precedence as tpu > cuda > rocm > host

```elixir
EXLA.set_preferred_defn_options([:tpu, :cuda, :rocm, :host])
```

## Encoder and decoder

The first step is defining the encoder and decoder. Both are one-layer neural nets.

In the encoder, we flatten the input using ```Axon.flatten``` because initially, it's image 28x28. Then we create a dense layer ```Axon.dense``` but with only ```latent_dim``` number of neurons (latent_dim < 28*28=784). The number of neurons has to be smaller than the length of the input vector since we need to compress the data.

Next, we pass the output of the encoder to the decoder. Now we try to remap compressed data into original ones. That's why we use ```Axon.dense``` with 784 neurons. In the end, there is an ```Axon.reshape``` to convert outputs into an image with correct width and height.

```elixir
defp encoder(x, latent_dim) do
  x
  |> Axon.flatten()
  |> Axon.dense(latent_dim, activation: :relu)
end

defp decoder(x) do
  x
  |> Axon.dense(784, activation: :sigmoid)
  |> Axon.reshape({1, 28, 28})
end
```

## Model

If we just bind the encoder and decoder into a sequential model, we'll get the desired model. This was pretty smooth, wasn't it?

```elixir
def build_model(input_shape, latent_dim) do
  Axon.input(input_shape)
  |> encoder(latent_dim)
  |> decoder()
end
```

## Preprocessing of the images

The next step is image preprocessing. First, we need to load the training data into tensor using ```Nx.from_binary``` and reshape with ```Nx.reshape```. Then normalize the data with ```Nx.divide``` and split the dataset into a list of batches with ```Nx.to_batched_list```.

```elixir
defp transform_images({bin, type, shape}) do
  bin
  |> Nx.from_binary(type)
  |> Nx.reshape({elem(shape, 0), 1, 28, 28})
  |> Nx.divide(255.0)
  |> Nx.to_batched_list(32)
end
```

## Training the model

Finally, we can train the model. We set model optimizer to *adam* and loss function to *MSE* with ```Axon.Loop.trainer```. To keep track of *MAE* use ```Axon.Loop.metric```. ```Axon.Loop.run``` trains the model with the given training data. Now we can test the autoencoder.

Let $$p(x)$$ will be the prediction for input $$x$$, $$X = (x_{1}, x_{2}, ..., x_{n})$$ is a vector of input values and $$Y = (y_{1}, y_{2}, ..., y_{n})$$ is a vector of target output

then

$$MSE(X, Y) = \frac{1}{n}\sum_{i=1}^{n} (p(x_{i})-y_{i})^{2}$$

and

$$MAE(X, Y) = \frac{1}{n}\sum_{i=1}^{n} |p(x_{i})-y_{i}|$$

```elixir
defp train_model(model, train_images, epochs) do
  model
  |> Axon.Loop.trainer(:mean_squared_error, :adam)
  |> Axon.Loop.metric(:mean_absolute_error, "Error")
  |> Axon.Loop.run(Stream.zip(train_images, train_images), epochs: epochs, compiler: EXLA)
end
```

## Evaluation of the model

To train and test how our model works, we use one of the most popular data set: MNIST fashion. It consists of small black and white images of clothes. Loading this data set is very simple. Just use ```Scidata.FashionMNIST.download()```.

```elixir
def run do
    {images, _} = Scidata.FashionMNIST.download()

    train_images = transform_images(images)

    model = Autoencoder.build_model({nil, 1, 28, 28}, 64) |> IO.inspect()

    model_state = train_model(model, train_images, 5)

    sample_image =
      train_images
      |> hd()
      |> Nx.slice_axis(0, 1, 0)
      |> Nx.reshape({1, 1, 28, 28})

    sample_image |> Nx.to_heatmap() |> IO.inspect()

    model
    |> Axon.predict(model_state, sample_image, compiler: EXLA)
    |> Nx.to_heatmap()
    |> IO.inspect()
  end
end
```

## Results analysis

As we can see, the generated image is similar to the input image. The only difference between them is the absence of a sign in the middle of the second shoe. The model treated the sign as noise and bled this into the plain shoe. To get the outputs run [this code](https://github.com/elixir-nx/axon/blob/main/examples/generative/fashionmnist_autoencoder.exs "Elixir module with Autoencoder").

```elixir
Fashionmist.run()
```
