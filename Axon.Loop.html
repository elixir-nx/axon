<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="ExDoc v0.26.0">
    <meta name="project" content="Axon v0.1.0-dev">

    <title>Axon.Loop â€” Axon v0.1.0-dev</title>
    <link rel="stylesheet" href="dist/elixir-b5076885a795c65e636c.css" />

    <script src="dist/sidebar_items-8284f7a6b1.js"></script>

      <script src="docs_config.js"></script>

    <script async src="dist/app-a404e1e870b77c874f9e.js"></script>


  </head>
  <body data-type="modules">
    <script>

      try {
        if (localStorage.getItem('night-mode') === 'true') {
          document.body.classList.add('night-mode');
        }
      } catch (error) { }
    </script>

<div class="main">

<button class="sidebar-button sidebar-toggle">
  <span class="icon-menu" title="Collapse/expand sidebar"></span>
</button>

<section class="sidebar">
  <form class="sidebar-search" action="search.html">
    <button type="submit" class="search-button" aria-label="Submit Search">
      <span class="icon-search" aria-hidden="true" title="Submit search"></span>
    </button>
    <button type="button" tabindex="-1" class="search-close-button" aria-label="Cancel Search">
      <span class="icon-cross" aria-hidden="true" title="Cancel search"></span>
    </button>
    <label class="search-label">
      <input name="q" type="text" class="search-input" placeholder="Search..." aria-label="Input your search terms" autocomplete="off" />
    </label>
  </form>

  <div class="autocomplete">
    <div class="autocomplete-results">
    </div>
  </div>

  <div class="sidebar-header">
    <div class="sidebar-projectDetails">
      <a href="Axon.html" class="sidebar-projectName" translate="no">
Axon
      </a>
      <strong class="sidebar-projectVersion" translate="no">
        v0.1.0-dev
      </strong>
    </div>

  </div>

  <ul class="sidebar-listNav">
    <li><a id="extras-list-link" href="#full-list">Pages</a></li>

      <li><a id="modules-list-link" href="#full-list">Modules</a></li>


  </ul>
  <div class="gradient"></div>
  <ul id="full-list" class="sidebar-fullList"></ul>
</section>

<section class="content">
  <div class="content-outer">
    <div id="content" class="content-inner">

<h1>
  <span translate="no">Axon.Loop</span> 
  <small class="app-vsn" translate="no">(Axon v0.1.0-dev)</small>

    <a href="https://github.com/elixir-nx/axon/blob/v0.1.0-dev/lib/axon/loop.ex#L1" title="View Source" class="view-source" rel="help">
      <span class="icon-code" aria-hidden="true"></span>
      <span class="sr-only">View Source</span>
    </a>


</h1>


  <section id="moduledoc">
<p>Abstraction for modeling a reduction of a dataset with an accumulated
state for a number of epochs.</p><p>Inspired heavily by <a href="https://pytorch.org/ignite/index.html">PyTorch Ignite</a>.</p><p>The main abstraction is the <code class="inline">%Loop{}</code> struct, which controls a nested
reduction of the form:</p><pre><code class="makeup elixir"><span class="nc">Enum</span><span class="o">.</span><span class="n">reduce</span><span class="p" data-group-id="1671333999-1">(</span><span class="mi">1</span><span class="o">..</span><span class="n">max_epochs</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p">,</span><span class="w"> </span><span class="k" data-group-id="1671333999-2">fn</span><span class="w"> </span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
  </span><span class="nc">Enum</span><span class="o">.</span><span class="n">reduce</span><span class="p" data-group-id="1671333999-3">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">batch_step</span><span class="o">/</span><span class="mi">2</span><span class="p" data-group-id="1671333999-3">)</span><span class="w">
</span><span class="k" data-group-id="1671333999-2">end</span><span class="p" data-group-id="1671333999-1">)</span></code></pre><p><code class="inline">data</code> is assumed to be an <a href="https://hexdocs.pm/elixir/Enumerable.html"><code class="inline">Enumerable</code></a> or <a href="https://hexdocs.pm/elixir/Stream.html"><code class="inline">Stream</code></a> of input data which is
handled by a processing function, <code class="inline">batch_step</code>. The purpose of the loop
abstraction is to take away much of the boilerplate used in solving machine
learning tasks. Tasks such as normalizing a dataset, hyperparameter optimization,
or training machine learning models boil down to writing one function:</p><pre><code class="makeup elixir"><span class="kd">defn</span><span class="w"> </span><span class="nf">batch_step</span><span class="p" data-group-id="9704539621-1">(</span><span class="n">batch</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p" data-group-id="9704539621-1">)</span><span class="w"> </span><span class="k" data-group-id="9704539621-2">do</span><span class="w">
  </span><span class="c1"># ...do something with batch...</span><span class="w">
  </span><span class="n">updated_state</span><span class="w">
</span><span class="k" data-group-id="9704539621-2">end</span></code></pre><p>For tasks such as training a neural network, <code class="inline">state</code> will encapsulate things
such as model and optimizer state. For supervised learning tasks, <code class="inline">batch_step</code>
might look something like:</p><pre><code class="makeup elixir"><span class="kd">defn</span><span class="w"> </span><span class="nf">batch_step</span><span class="p" data-group-id="4563325599-1">(</span><span class="p" data-group-id="4563325599-2">{</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p" data-group-id="4563325599-2">}</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p" data-group-id="4563325599-1">)</span><span class="w"> </span><span class="k" data-group-id="4563325599-3">do</span><span class="w">
  </span><span class="p" data-group-id="4563325599-4">%{</span><span class="ss">parameters</span><span class="p">:</span><span class="w"> </span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="ss">optimizer_state</span><span class="p">:</span><span class="w"> </span><span class="n">optim_state</span><span class="p" data-group-id="4563325599-4">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">state</span><span class="w">

  </span><span class="n">gradients</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">grad</span><span class="p" data-group-id="4563325599-5">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">objective_fn</span><span class="o">.</span><span class="p" data-group-id="4563325599-6">(</span><span class="ni">&amp;1</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p" data-group-id="4563325599-6">)</span><span class="p" data-group-id="4563325599-5">)</span><span class="w">
  </span><span class="p" data-group-id="4563325599-7">{</span><span class="n">updates</span><span class="p">,</span><span class="w"> </span><span class="n">new_optim_state</span><span class="p" data-group-id="4563325599-7">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">optimizer</span><span class="o">.</span><span class="p" data-group-id="4563325599-8">(</span><span class="n">optim_state</span><span class="p">,</span><span class="w"> </span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">gradients</span><span class="p" data-group-id="4563325599-8">)</span><span class="w">

  </span><span class="n">new_params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">apply_updates</span><span class="p" data-group-id="4563325599-9">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">updates</span><span class="p" data-group-id="4563325599-9">)</span><span class="w">

  </span><span class="p" data-group-id="4563325599-10">%{</span><span class="ss">parameters</span><span class="p">:</span><span class="w"> </span><span class="n">new_params</span><span class="p">,</span><span class="w"> </span><span class="ss">optimizer_state</span><span class="p">:</span><span class="w"> </span><span class="n">optim_state</span><span class="p" data-group-id="4563325599-10">}</span><span class="w">
</span><span class="k" data-group-id="4563325599-3">end</span></code></pre><p><code class="inline">batch_step</code> takes a batch of <code class="inline">{input, target}</code> pairs and the current state,
and updates the model parameters based on the gradients received from some arbitrary
objective function. This function will run in a nested loop, iterating over the entire
dataset for <code class="inline">N</code> epochs before finally returning the trained model state. By defining
1 function, we've created a training loop that works for most machine learning models.</p><p>In actuality, the loop abstraction accumulates a struct, <a href="Axon.Loop.State.html"><code class="inline">Axon.Loop.State</code></a>, which looks
like (assuming <code class="inline">container</code> is a generic Elixir container of tensors, e.g. map, tuple, etc.):</p><pre><code class="makeup elixir"><span class="p" data-group-id="1105344890-1">%</span><span class="nc" data-group-id="1105344890-1">State</span><span class="p" data-group-id="1105344890-1">{</span><span class="w">
  </span><span class="ss">epoch</span><span class="p">:</span><span class="w"> </span><span class="n">tensor</span><span class="p" data-group-id="1105344890-2">(</span><span class="p" data-group-id="1105344890-2">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">max_epoch</span><span class="p">:</span><span class="w"> </span><span class="n">tensor</span><span class="p" data-group-id="1105344890-3">(</span><span class="p" data-group-id="1105344890-3">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">iteration</span><span class="p">:</span><span class="w"> </span><span class="n">tensor</span><span class="p" data-group-id="1105344890-4">(</span><span class="p" data-group-id="1105344890-4">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">max_iteration</span><span class="p">:</span><span class="w"> </span><span class="n">tensor</span><span class="p" data-group-id="1105344890-5">(</span><span class="p" data-group-id="1105344890-5">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">metrics</span><span class="p">:</span><span class="w"> </span><span class="n">map</span><span class="p" data-group-id="1105344890-6">(</span><span class="n">string</span><span class="p" data-group-id="1105344890-7">(</span><span class="p" data-group-id="1105344890-7">)</span><span class="p">,</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="1105344890-8">(</span><span class="p" data-group-id="1105344890-8">)</span><span class="p" data-group-id="1105344890-6">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">times</span><span class="p">:</span><span class="w"> </span><span class="n">list</span><span class="p" data-group-id="1105344890-9">(</span><span class="n">number</span><span class="p" data-group-id="1105344890-10">(</span><span class="p" data-group-id="1105344890-10">)</span><span class="p" data-group-id="1105344890-9">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">step_state</span><span class="p">:</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="1105344890-11">(</span><span class="p" data-group-id="1105344890-11">)</span><span class="w">
</span><span class="p" data-group-id="1105344890-1">}</span></code></pre><p><code class="inline">batch_step</code> takes in the batch and the step state field and returns a <code class="inline">step_state</code>,
which is a generic container of state accumulated at each iteration. The rest of the fields
in the state struct are updated automatically behind the scenes.</p><p>The loop must start from some initial step state, thus most tasks must also provide
an additional initialization function to provide some starting point for the step
state. For machine learning tasks, the initialization function will return things like
initial model parameters and optimizer state.</p><p>Typically, the final output of the loop is the accumulated final state; however, you
may optionally apply an output transform to extract specific values at the end of the
loop. For example, <code class="inline">Axon.Loop.trainer/4</code> by default extracts trained model state:</p><pre><code class="makeup elixir"><span class="n">output_transform</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k" data-group-id="7676078492-1">fn</span><span class="w"> </span><span class="n">state</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
  </span><span class="n">state</span><span class="o">.</span><span class="n">step_state</span><span class="p" data-group-id="7676078492-2">[</span><span class="ss">:model_state</span><span class="p" data-group-id="7676078492-2">]</span><span class="w">
</span><span class="k" data-group-id="7676078492-1">end</span></code></pre><h2 id="module-initialize-and-step" class="section-heading">
  <a href="#module-initialize-and-step" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Initialize and Step
</h2>
<p>The core of the Axon loop are the init and step functions. The initialization is an
arity-0 function which provides an initial step state:</p><pre><code class="makeup elixir"><span class="n">init</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k" data-group-id="7292428198-1">fn</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
  </span><span class="p" data-group-id="7292428198-2">%{</span><span class="ss">params</span><span class="p">:</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">init</span><span class="p" data-group-id="7292428198-3">(</span><span class="n">model</span><span class="p" data-group-id="7292428198-3">)</span><span class="p" data-group-id="7292428198-2">}</span><span class="w">
</span><span class="k" data-group-id="7292428198-1">end</span></code></pre><p>While the step function is the <code class="inline">batch_step</code> function mentioned earlier:</p><pre><code class="makeup elixir"><span class="n">step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k" data-group-id="9552229434-1">fn</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
  </span><span class="n">new_state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="c1"># ...do something...</span><span class="w">
  </span><span class="n">new_state</span><span class="w">
</span><span class="k" data-group-id="9552229434-1">end</span></code></pre><h2 id="module-metrics" class="section-heading">
  <a href="#module-metrics" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Metrics
</h2>
<p>Often times you want to compute metrics assosciated with your training iterations.
To accomplish this, you can attach metrics to each <a href="Axon.Loop.html#content"><code class="inline">Axon.Loop</code></a>. Assuming a <code class="inline">batch_step</code>
function which looks like:</p><pre><code class="makeup elixir"><span class="kd">defn</span><span class="w"> </span><span class="nf">batch_step</span><span class="p" data-group-id="9100857248-1">(</span><span class="p" data-group-id="9100857248-2">{</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p" data-group-id="9100857248-2">}</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p" data-group-id="9100857248-1">)</span><span class="w"> </span><span class="k" data-group-id="9100857248-3">do</span><span class="w">
  </span><span class="p" data-group-id="9100857248-4">%{</span><span class="ss">parameters</span><span class="p">:</span><span class="w"> </span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="ss">optimizer_state</span><span class="p">:</span><span class="w"> </span><span class="n">optim_state</span><span class="p" data-group-id="9100857248-4">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">state</span><span class="w">

  </span><span class="n">gradients</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">grad</span><span class="p" data-group-id="9100857248-5">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">objective_fn</span><span class="o">.</span><span class="p" data-group-id="9100857248-6">(</span><span class="ni">&amp;1</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p" data-group-id="9100857248-6">)</span><span class="p" data-group-id="9100857248-5">)</span><span class="w">
  </span><span class="p" data-group-id="9100857248-7">{</span><span class="n">updates</span><span class="p">,</span><span class="w"> </span><span class="n">new_optim_state</span><span class="p" data-group-id="9100857248-7">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">optimizer</span><span class="o">.</span><span class="p" data-group-id="9100857248-8">(</span><span class="n">optim_state</span><span class="p">,</span><span class="w"> </span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">gradients</span><span class="p" data-group-id="9100857248-8">)</span><span class="w">

  </span><span class="n">new_params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">apply_updates</span><span class="p" data-group-id="9100857248-9">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">updates</span><span class="p" data-group-id="9100857248-9">)</span><span class="w">

  </span><span class="c1"># Shown for simplicity, you can optimize this by calculating preds</span><span class="w">
  </span><span class="c1"># along with the gradient calculation</span><span class="w">
  </span><span class="n">preds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_fn</span><span class="o">.</span><span class="p" data-group-id="9100857248-10">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p" data-group-id="9100857248-10">)</span><span class="w">

  </span><span class="p" data-group-id="9100857248-11">%{</span><span class="w">
    </span><span class="ss">y_true</span><span class="p">:</span><span class="w"> </span><span class="n">targets</span><span class="p">,</span><span class="w">
    </span><span class="ss">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">preds</span><span class="p">,</span><span class="w">
    </span><span class="ss">parameters</span><span class="p">:</span><span class="w"> </span><span class="n">new_params</span><span class="p">,</span><span class="w">
    </span><span class="ss">optimizer_state</span><span class="p">:</span><span class="w"> </span><span class="n">optim_state</span><span class="w">
  </span><span class="p" data-group-id="9100857248-11">}</span><span class="w">
</span><span class="k" data-group-id="9100857248-3">end</span></code></pre><p>You can attach metrics to this by using <a href="#metric/4"><code class="inline">Axon.Loop.metric/4</code></a>:</p><pre><code class="makeup elixir"><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">loop</span><span class="p" data-group-id="1263071364-1">(</span><span class="o">&amp;</span><span class="n">batch_step</span><span class="o">/</span><span class="mi">2</span><span class="p" data-group-id="1263071364-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="1263071364-2">(</span><span class="s">&quot;Accuracy&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">:accuracy</span><span class="p">,</span><span class="w"> </span><span class="k" data-group-id="1263071364-3">fn</span><span class="w"> </span><span class="p" data-group-id="1263071364-4">%{</span><span class="ss">y_true</span><span class="p">:</span><span class="w"> </span><span class="n">y_</span><span class="p">,</span><span class="w"> </span><span class="ss">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">y</span><span class="p" data-group-id="1263071364-4">}</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p" data-group-id="1263071364-5">[</span><span class="n">y_</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p" data-group-id="1263071364-5">]</span><span class="w"> </span><span class="k" data-group-id="1263071364-3">end</span><span class="p" data-group-id="1263071364-2">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="1263071364-6">(</span><span class="n">data</span><span class="p" data-group-id="1263071364-6">)</span></code></pre><p>Because metrics work directly on <code class="inline">step_state</code>, you typically need to provide an output
transform to indicate which values should be passed to your metric function. By default,
Axon assumes a supervised training task with the fields <code class="inline">:y_true</code> and <code class="inline">:y_pred</code> present
in the step state. See <a href="#metric/4"><code class="inline">Axon.Loop.metric/4</code></a> for more information.</p><p>Metrics will be tracked in the loop state using the user-provided key. Metrics integrate
seamlessly with the supervised metrics defined in <a href="Axon.Metrics.html"><code class="inline">Axon.Metrics</code></a>. You can also use metrics
to keep running averages of some values in the original dataset.</p><h2 id="module-events-and-handlers" class="section-heading">
  <a href="#module-events-and-handlers" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Events and Handlers
</h2>
<p>You can instrument several points in the loop using event handlers. By default, several events
are fired when running a loop:</p><pre><code class="makeup elixir"><span class="n">events</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="7866624538-1">[</span><span class="w">
  </span><span class="ss">:started</span><span class="p">,</span><span class="w">             </span><span class="c1"># After loop state initialization</span><span class="w">
  </span><span class="ss">:epoch_started</span><span class="p">,</span><span class="w">       </span><span class="c1"># On epoch start</span><span class="w">
  </span><span class="ss">:iteration_started</span><span class="p">,</span><span class="w">   </span><span class="c1"># On iteration start</span><span class="w">
  </span><span class="ss">:iteration_completed</span><span class="p">,</span><span class="w"> </span><span class="c1"># On iteration complete</span><span class="w">
  </span><span class="ss">:epoch_completed</span><span class="p">,</span><span class="w">     </span><span class="c1"># On epoch complete</span><span class="w">
  </span><span class="ss">:epoch_halted</span><span class="p">,</span><span class="w">        </span><span class="c1"># On epoch halt, if early halted</span><span class="w">
  </span><span class="ss">:halted</span><span class="p">,</span><span class="w">              </span><span class="c1"># On loop halt, if early halted</span><span class="w">
  </span><span class="ss">:completed</span><span class="w">            </span><span class="c1"># On loop completion</span><span class="w">
</span><span class="p" data-group-id="7866624538-1">]</span></code></pre><p>You can attach event handlers to events using <a href="#handle/4"><code class="inline">Axon.Loop.handle/4</code></a>:</p><pre><code class="makeup elixir"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">handle</span><span class="p" data-group-id="2783759886-1">(</span><span class="ss">:iteration_completed</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">log_metrics</span><span class="o">/</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="ss">every</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p" data-group-id="2783759886-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="2783759886-2">(</span><span class="n">data</span><span class="p" data-group-id="2783759886-2">)</span></code></pre><p>The above will trigger <code class="inline">log_metrics/1</code> every 100 times the <code class="inline">:iteration_completed</code> event
is fired. Event handlers must return a tuple <code class="inline">{status, state}</code>, where <code class="inline">status</code> is an
atom with one of the following values:</p><pre><code class="makeup elixir"><span class="ss">:continue</span><span class="w">   </span><span class="c1"># Continue epoch, continue looping</span><span class="w">
</span><span class="ss">:halt_epoch</span><span class="w"> </span><span class="c1"># Halt the epoch, continue looping</span><span class="w">
</span><span class="ss">:halt_loop</span><span class="w">  </span><span class="c1"># Halt looping</span></code></pre><p>And <code class="inline">state</code> is an updated <a href="Axon.Loop.State.html"><code class="inline">Axon.Loop.State</code></a> struct. Handler functions take as input
the current loop state.</p><p>It's important to note that event handlers are triggered in the order they are attached
to the loop. If you have two handlers on the same event, they will trigger in order:</p><pre><code class="makeup elixir"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">handle</span><span class="p" data-group-id="7344450919-1">(</span><span class="ss">:epoch_completed</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">normalize_state</span><span class="o">/</span><span class="mi">1</span><span class="p" data-group-id="7344450919-1">)</span><span class="w"> </span><span class="c1"># Runs first</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">handle</span><span class="p" data-group-id="7344450919-2">(</span><span class="ss">:epoch_completed</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">log_state</span><span class="o">/</span><span class="mi">1</span><span class="p" data-group-id="7344450919-2">)</span><span class="w"> </span><span class="c1"># Runs second</span></code></pre><p>You may provide filters to filter when event handlers trigger. See <a href="#handle/4"><code class="inline">Axon.Loop.handle/4</code></a>
for more details on valid filters.</p><h2 id="module-factories" class="section-heading">
  <a href="#module-factories" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Factories
</h2>
<p>Axon loops are typically created from one of the factory functions provided in this
module:</p><pre><code class="makeup elixir"><span class="o">*</span><span class="w"> </span><span class="err">`</span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">loop</span><span class="o">/</span><span class="mi">3</span><span class="err">`</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nc">Creates</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">loop</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="n">function</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">optional</span><span class="w"> </span><span class="n">initialization</span><span class="w">
</span><span class="n">functions</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">transform</span><span class="w"> </span><span class="n">functions</span><span class="o">.</span><span class="w">

</span><span class="o">*</span><span class="w"> </span><span class="err">`</span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="o">/</span><span class="mi">3</span><span class="err">`</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nc">Creates</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">supervised</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">loop</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w">
</span><span class="n">optimizer</span><span class="o">.</span><span class="w">

</span><span class="o">*</span><span class="w"> </span><span class="err">`</span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">evaluator</span><span class="o">/</span><span class="mi">2</span><span class="err">`</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nc">Creates</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">supervised</span><span class="w"> </span><span class="n">evaluator</span><span class="w"> </span><span class="n">loop</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">model</span><span class="w">
</span><span class="n">state</span><span class="o">.</span></code></pre><h2 id="module-running-loops" class="section-heading">
  <a href="#module-running-loops" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Running loops
</h2>
<p>In order to execute a loop, you should use <a href="#run/3"><code class="inline">Axon.Loop.run/3</code></a>:</p><pre><code class="makeup elixir"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="8282501016-1">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="ss">epochs</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="p" data-group-id="8282501016-1">)</span></code></pre><h2 id="module-resuming-loops" class="section-heading">
  <a href="#module-resuming-loops" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Resuming loops
</h2>
<p>At times you may want to resume a loop from some previous state. You can accomplish this
with <a href="#from_state/2"><code class="inline">Axon.Loop.from_state/2</code></a>:</p><pre><code class="makeup elixir"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">from_state</span><span class="p" data-group-id="8081123279-1">(</span><span class="n">state</span><span class="p" data-group-id="8081123279-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="8081123279-2">(</span><span class="n">data</span><span class="p" data-group-id="8081123279-2">)</span></code></pre>
  </section>


  <section id="summary" class="details-list">
    <h1 class="section-heading">
      <a class="hover-link" href="#summary">
        <span class="icon-link" aria-hidden="true"></span>
        <span class="sr-only">Link to this section</span>
      </a>
      Summary
    </h1>

  <div class="summary-functions summary">
    <h2>
      <a href="#functions">Functions</a>
    </h2>

      <div class="summary-row">
        <div class="summary-signature">
          <a href="#eval_step/2" translate="no">eval_step(model, model_state)</a>

        </div>

          <div class="summary-synopsis"><p>Creates a supervised evaluation step from a model and model state.</p></div>

      </div>

      <div class="summary-row">
        <div class="summary-signature">
          <a href="#evaluator/2" translate="no">evaluator(model, model_state)</a>

        </div>

          <div class="summary-synopsis"><p>Creates a supervised evaluator from a model and model state.</p></div>

      </div>

      <div class="summary-row">
        <div class="summary-signature">
          <a href="#from_state/2" translate="no">from_state(loop, state)</a>

        </div>

          <div class="summary-synopsis"><p>Attaches <code class="inline">state</code> to the given loop in order to resume looping
from a previous state.</p></div>

      </div>

      <div class="summary-row">
        <div class="summary-signature">
          <a href="#handle/4" translate="no">handle(loop, event, handler, filter \\ :always)</a>

        </div>

          <div class="summary-synopsis"><p>Adds a handler function to the loop which will be triggered on <code class="inline">event</code>
with an optional filter.</p></div>

      </div>

      <div class="summary-row">
        <div class="summary-signature">
          <a href="#loop/3" translate="no">loop(step_fn, init_fn \\ fn -&gt; %{} end, output_transform \\ &amp;(&amp;1))</a>

        </div>

          <div class="summary-synopsis"><p>Creates a loop from <code class="inline">step_fn</code>, an optional <code class="inline">init_fn</code>, and an
optional <code class="inline">output_transform</code>.</p></div>

      </div>

      <div class="summary-row">
        <div class="summary-signature">
          <a href="#metric/5" translate="no">metric(loop, metric, name \\ nil, accumulate \\ :running_average, transform_or_fields \\ [:y_true, :y_pred])</a>

        </div>

          <div class="summary-synopsis"><p>Adds a metric of the given name to the loop.</p></div>

      </div>

      <div class="summary-row">
        <div class="summary-signature">
          <a href="#run/3" translate="no">run(loop, data, opts \\ [])</a>

        </div>

          <div class="summary-synopsis"><p>Runs the given loop on data with the given options.</p></div>

      </div>

      <div class="summary-row">
        <div class="summary-signature">
          <a href="#train_step/3" translate="no">train_step(model, loss, optimizer)</a>

        </div>

          <div class="summary-synopsis"><p>Creates a supervised train step from a model, loss function, and
optimizer.</p></div>

      </div>

      <div class="summary-row">
        <div class="summary-signature">
          <a href="#trainer/3" translate="no">trainer(model, loss, optimizer)</a>

        </div>

          <div class="summary-synopsis"><p>Creates a supervised training loop from a model, loss function,
and optimizer.</p></div>

      </div>

  </div>

  </section>


  <section id="functions" class="details-list">
    <h1 class="section-heading">
      <a class="hover-link" href="#functions">
        <span class="icon-link" aria-hidden="true"></span>
        <span class="sr-only">Link to this section</span>
      </a>
Functions
    </h1>
    <div class="functions-list">
<section class="detail" id="eval_step/2">

  <div class="detail-header">
    <a href="#eval_step/2" class="detail-link" title="Link to this function">
      <span class="icon-link" aria-hidden="true"></span>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">eval_step(model, model_state)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.1.0-dev/lib/axon/loop.ex#L369" class="view-source" rel="help" title="View Source">
       <span class="icon-code" aria-hidden="true"></span>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Creates a supervised evaluation step from a model and model state.</p><p>This function is intended for more fine-grained control over the loop
creation process. It returns a tuple of <code class="inline">{init_fn, step_fn}</code> where
<code class="inline">init_fn</code> returns an initial step state and <code class="inline">step_fn</code> performs a
single evaluation step.</p>
  </section>
</section>
<section class="detail" id="evaluator/2">

  <div class="detail-header">
    <a href="#evaluator/2" class="detail-link" title="Link to this function">
      <span class="icon-link" aria-hidden="true"></span>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">evaluator(model, model_state)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.1.0-dev/lib/axon/loop.ex#L539" class="view-source" rel="help" title="View Source">
       <span class="icon-code" aria-hidden="true"></span>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Creates a supervised evaluator from a model and model state.</p><p>An evaluator can be used for things such as testing and validation of models
after or during training. It assumes <code class="inline">model</code> is an Axon struct, container of
structs, or a tuple of <code class="inline">init</code> / <code class="inline">apply</code> functions. <code class="inline">model_state</code> must be a
container useable from within <code class="inline">model</code>.</p><p>The evaluator returns a step state of the form:</p><pre><code class="makeup elixir"><span class="p" data-group-id="0349937921-1">%{</span><span class="w">
  </span><span class="ss">y_true</span><span class="p">:</span><span class="w"> </span><span class="n">labels</span><span class="p">,</span><span class="w">
  </span><span class="ss">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">predictions</span><span class="w">
</span><span class="p" data-group-id="0349937921-1">}</span></code></pre><p>Such that you can attach any number of supervised metrics to the evaluation
loop:</p><pre><code class="makeup elixir"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">evaluator</span><span class="p" data-group-id="5531952948-1">(</span><span class="n">trained_state</span><span class="p" data-group-id="5531952948-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="5531952948-2">(</span><span class="s">&quot;Accuracy&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">:accuracy</span><span class="p" data-group-id="5531952948-2">)</span></code></pre><p>Applies an output transform which returns the map of metrics accumulated over
the given loop.</p>
  </section>
</section>
<section class="detail" id="from_state/2">

  <div class="detail-header">
    <a href="#from_state/2" class="detail-link" title="Link to this function">
      <span class="icon-link" aria-hidden="true"></span>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">from_state(loop, state)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.1.0-dev/lib/axon/loop.ex#L714" class="view-source" rel="help" title="View Source">
       <span class="icon-code" aria-hidden="true"></span>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Attaches <code class="inline">state</code> to the given loop in order to resume looping
from a previous state.</p><p>It's important to note that a loop's attached state takes precedence
over defined initialization functions. Given initialization function:</p><pre><code class="makeup elixir"><span class="kd">defn</span><span class="w"> </span><span class="nf">init_state</span><span class="p" data-group-id="3471144395-1">(</span><span class="p" data-group-id="3471144395-1">)</span><span class="p">,</span><span class="w"> </span><span class="ss">do</span><span class="p">:</span><span class="w"> </span><span class="p" data-group-id="3471144395-2">%{</span><span class="ss">foo</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="ss">bar</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p" data-group-id="3471144395-2">}</span></code></pre><p>And an attached state:</p><pre><code class="makeup elixir"><span class="n">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="2996818205-1">%</span><span class="nc" data-group-id="2996818205-1">State</span><span class="p" data-group-id="2996818205-1">{</span><span class="ss">step_state</span><span class="p">:</span><span class="w"> </span><span class="p" data-group-id="2996818205-2">%{</span><span class="ss">foo</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="ss">bar</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p" data-group-id="2996818205-2">}</span><span class="p" data-group-id="2996818205-1">}</span></code></pre><p><code class="inline">init_state/0</code> will never execute, and instead the initial step state
of <code class="inline">%{foo: 2, bar: 3}</code> will be used.</p>
  </section>
</section>
<section class="detail" id="handle/4">

    <span id="handle/3"></span>

  <div class="detail-header">
    <a href="#handle/4" class="detail-link" title="Link to this function">
      <span class="icon-link" aria-hidden="true"></span>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">handle(loop, event, handler, filter \\ :always)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.1.0-dev/lib/axon/loop.ex#L680" class="view-source" rel="help" title="View Source">
       <span class="icon-code" aria-hidden="true"></span>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a handler function to the loop which will be triggered on <code class="inline">event</code>
with an optional filter.</p><p>Events take place at different points during loop execution. The default
events are:</p><pre><code class="makeup elixir"><span class="n">events</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="7323959377-1">[</span><span class="w">
  </span><span class="ss">:started</span><span class="p">,</span><span class="w">             </span><span class="c1"># After loop state initialization</span><span class="w">
  </span><span class="ss">:epoch_started</span><span class="p">,</span><span class="w">       </span><span class="c1"># On epoch start</span><span class="w">
  </span><span class="ss">:iteration_started</span><span class="p">,</span><span class="w">   </span><span class="c1"># On iteration start</span><span class="w">
  </span><span class="ss">:iteration_completed</span><span class="p">,</span><span class="w"> </span><span class="c1"># On iteration complete</span><span class="w">
  </span><span class="ss">:epoch_completed</span><span class="p">,</span><span class="w">     </span><span class="c1"># On epoch complete</span><span class="w">
  </span><span class="ss">:epoch_halted</span><span class="p">,</span><span class="w">        </span><span class="c1"># On epoch halt, if early halted</span><span class="w">
  </span><span class="ss">:halted</span><span class="p">,</span><span class="w">              </span><span class="c1"># On loop halt, if early halted</span><span class="w">
  </span><span class="ss">:completed</span><span class="w">            </span><span class="c1"># On loop completion</span><span class="w">
</span><span class="p" data-group-id="7323959377-1">]</span></code></pre><p>Generally, event handlers are side-effecting operations which provide some
sort of inspection into the loop's progress. It's important to note that
if you define multiple handlers to be triggered on the same event, they
will execute in order from when they were attached to the training
loop:</p><pre><code class="makeup elixir"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">handle</span><span class="p" data-group-id="6963824077-1">(</span><span class="ss">:epoch_started</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">normalize_step_state</span><span class="o">/</span><span class="mi">1</span><span class="p" data-group-id="6963824077-1">)</span><span class="w"> </span><span class="c1"># executes first</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">handle</span><span class="p" data-group-id="6963824077-2">(</span><span class="ss">:epoch_started</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">log_step_state</span><span class="o">/</span><span class="mi">1</span><span class="p" data-group-id="6963824077-2">)</span><span class="w"> </span><span class="c1"># executes second</span></code></pre><p>Thus, if you have separate handlers which alter or depend on loop state,
you need to ensure they are ordered correctly, or combined into a single
event handler for maximum control over execution.</p><p><code class="inline">event</code> must be an atom representing the event to trigger <code class="inline">handler</code> or a
list of atoms indicating <code class="inline">handler</code> should be triggered on multiple events.
<code class="inline">event</code> may be <code class="inline">:all</code> which indicates the handler should be triggered on
every event during loop processing.</p><p><code class="inline">handler</code> must be an arity-1 function which takes as input loop state and
returns <code class="inline">{status, state}</code>, where <code class="inline">status</code> is an atom with one of the following
values:</p><pre><code class="makeup elixir"><span class="ss">:continue</span><span class="w">   </span><span class="c1"># Continue epoch, continue looping</span><span class="w">
</span><span class="ss">:halt_epoch</span><span class="w"> </span><span class="c1"># Halt the epoch, continue looping</span><span class="w">
</span><span class="ss">:halt_loop</span><span class="w">  </span><span class="c1"># Halt looping</span></code></pre><p><code class="inline">filter</code> is an atom representing a valid filter predicate, a keyword of
predicate-value pairs, or a function which takes loop state and returns
a <code class="inline">true</code>, indicating the handler should run, or <code class="inline">false</code>, indicating the
handler should not run. Valid predicates are:</p><pre><code class="makeup elixir"><span class="ss">:always</span><span class="w"> </span><span class="c1"># Always trigger event</span><span class="w">
</span><span class="ss">:once</span><span class="w">   </span><span class="c1"># Trigger on first event firing</span></code></pre><p>Valid predicate-value pairs are:</p><pre><code class="makeup elixir"><span class="ss">every</span><span class="p">:</span><span class="w"> </span><span class="nc">N</span><span class="w"> </span><span class="c1"># Trigger every `N` event</span><span class="w">
</span><span class="ss">only</span><span class="p">:</span><span class="w"> </span><span class="nc">N</span><span class="w"> </span><span class="c1"># Trigger on `N` event</span></code></pre>
  </section>
</section>
<section class="detail" id="loop/3">

    <span id="loop/1"></span>

    <span id="loop/2"></span>

  <div class="detail-header">
    <a href="#loop/3" class="detail-link" title="Link to this function">
      <span class="icon-link" aria-hidden="true"></span>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">loop(step_fn, init_fn \\ fn -&gt; %{} end, output_transform \\ &amp;(&amp;1))</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.1.0-dev/lib/axon/loop.ex#L419" class="view-source" rel="help" title="View Source">
       <span class="icon-code" aria-hidden="true"></span>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Creates a loop from <code class="inline">step_fn</code>, an optional <code class="inline">init_fn</code>, and an
optional <code class="inline">output_transform</code>.</p><p><code class="inline">step_fn</code> is an arity-2 function which takes a batch and state
and returns an updated step state:</p><pre><code class="makeup elixir"><span class="kd">defn</span><span class="w"> </span><span class="nf">batch_step</span><span class="p" data-group-id="6469507596-1">(</span><span class="n">batch</span><span class="p">,</span><span class="w"> </span><span class="n">step_state</span><span class="p" data-group-id="6469507596-1">)</span><span class="w"> </span><span class="k" data-group-id="6469507596-2">do</span><span class="w">
  </span><span class="n">step_state</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w">
</span><span class="k" data-group-id="6469507596-2">end</span></code></pre><p><code class="inline">init_fn</code> by default is a function which returns an empty map. You should
define your own if subsequent step state updates rely on an initial
step state:</p><pre><code class="makeup elixir"><span class="kd">defn</span><span class="w"> </span><span class="nf">init_step_state</span><span class="p" data-group-id="7059345576-1">(</span><span class="p" data-group-id="7059345576-1">)</span><span class="w"> </span><span class="k" data-group-id="7059345576-2">do</span><span class="w">
  </span><span class="mi">0</span><span class="w">
</span><span class="k" data-group-id="7059345576-2">end</span></code></pre><p><code class="inline">step_batch/2</code> and <code class="inline">init_step_state/0</code> are typically called from
within <a href="https://hexdocs.pm/nx/0.1.0-dev/Nx.Defn.html#jit/3"><code class="inline">Nx.Defn.jit/3</code></a>. While JIT-compilation will work with anonymous functions,
<code class="inline">def</code>, and <code class="inline">defn</code>, it is recommended that you use the stricter <code class="inline">defn</code> to define
both functions in order to avoid bugs or cryptic errors.</p><p><code class="inline">output_transform/1</code> applies a transformation on the final accumulated loop state.
This is useful for extracting specific fields from a loop and piping them into
additional functions.</p>
  </section>
</section>
<section class="detail" id="metric/5">

    <span id="metric/2"></span>

    <span id="metric/3"></span>

    <span id="metric/4"></span>

  <div class="detail-header">
    <a href="#metric/5" class="detail-link" title="Link to this function">
      <span class="icon-link" aria-hidden="true"></span>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">metric(loop, metric, name \\ nil, accumulate \\ :running_average, transform_or_fields \\ [:y_true, :y_pred])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.1.0-dev/lib/axon/loop.ex#L587" class="view-source" rel="help" title="View Source">
       <span class="icon-code" aria-hidden="true"></span>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a metric of the given name to the loop.</p><p>A metric is a function which tracks or measures some value with respect
to values in the step state. For example, when training classification
models, it's common to track the model's accuracy during training:</p><pre><code class="makeup elixir"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="1300945266-1">(</span><span class="ss">:accuracy</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Accuracy&quot;</span><span class="p" data-group-id="1300945266-1">)</span></code></pre><p>By default, metrics assume a supervised learning task and extract the fields
<code class="inline">[:y_true, :y_pred]</code> from the step state. If you wish to work on a different
value, you can use an output transform. An output transform is a list of keys
to extract from the output state, or a function which returns a flattened list
of values to pass to the given metric function. Values received from output
transforms are passed to the given metric using:</p><pre><code class="makeup elixir"><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output_transform</span><span class="o">.</span><span class="p" data-group-id="0025598029-1">(</span><span class="n">step_state</span><span class="p" data-group-id="0025598029-1">)</span><span class="w">
</span><span class="n">apply</span><span class="p" data-group-id="0025598029-2">(</span><span class="n">metric</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p" data-group-id="0025598029-2">)</span></code></pre><p>Thus, even if you want your metric to work on a container, your output transform
must return a list.</p><p><code class="inline">metric</code> must be an atom which matches the name of a metric in <a href="Axon.Metrics.html"><code class="inline">Axon.Metrics</code></a>, or
an arbitrary function which returns a tensor or container.</p><p><code class="inline">name</code> must be a string or atom used to store the computed metric in the loop
state. If names conflict, the last attached metric will take precedence:</p><pre><code class="makeup elixir"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="3797537714-1">(</span><span class="ss">:mean_squared_error</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Error&quot;</span><span class="p" data-group-id="3797537714-1">)</span><span class="w"> </span><span class="c1"># Will be overwritten</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="3797537714-2">(</span><span class="ss">:mean_absolute_error</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Error&quot;</span><span class="p" data-group-id="3797537714-2">)</span><span class="w"> </span><span class="c1"># Will be used</span></code></pre><p>By default, metrics keep a running average of the metric calculation. You can
override this behavior by changing <code class="inline">accumulate</code>:</p><pre><code class="makeup elixir"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="8502607222-1">(</span><span class="ss">:true_negatives</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;tn&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">:running_sum</span><span class="p" data-group-id="8502607222-1">)</span></code></pre><p>Accumulation function can be one of the accumulation combinators in Axon.Metrics
or an arity-3 function of the form: <code class="inline">accumulate(acc, obs, i) :: new_acc</code>.</p>
  </section>
</section>
<section class="detail" id="run/3">

    <span id="run/2"></span>

  <div class="detail-header">
    <a href="#run/3" class="detail-link" title="Link to this function">
      <span class="icon-link" aria-hidden="true"></span>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">run(loop, data, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.1.0-dev/lib/axon/loop.ex#L742" class="view-source" rel="help" title="View Source">
       <span class="icon-code" aria-hidden="true"></span>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Runs the given loop on data with the given options.</p><p><code class="inline">loop</code> must be a valid Axon.Loop struct built from one of the
loop factories provided in this module.</p><p><code class="inline">data</code> must be an Enumerable or Stream which yields batches of
data on each iteration.</p><h2 id="run/3-options" class="section-heading">
  <a href="#run/3-options" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Options
</h2>
<ul><li><p><code class="inline">:epochs</code> - max epochs to run loop for. Must be non-negative integer.
Defaults to <code class="inline">1</code>.</p></li><li><p><code class="inline">:iterations</code> - max iterations to run each epoch. Must be non-negative
integer. Defaults to <code class="inline">nil</code> or no max iterations.</p></li><li><p><code class="inline">:jit_compile?</code> - whether or not to JIT compile initialization and step
functions. JIT compilation must be used for gradient computations. Defaults
to true.</p></li><li><p><code class="inline">:compiler</code> - Nx compiler to use to JIT compile step function. Defaults
to <code class="inline">nil</code> or Nx.Defn.Evaluator.</p></li></ul>
  </section>
</section>
<section class="detail" id="train_step/3">

  <div class="detail-header">
    <a href="#train_step/3" class="detail-link" title="Link to this function">
      <span class="icon-link" aria-hidden="true"></span>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">train_step(model, loss, optimizer)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.1.0-dev/lib/axon/loop.ex#L304" class="view-source" rel="help" title="View Source">
       <span class="icon-code" aria-hidden="true"></span>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Creates a supervised train step from a model, loss function, and
optimizer.</p><p>This function is intended for more fine-grained control over the loop
creation process. It returns a tuple of <code class="inline">{init_fn, step_fn}</code> where <code class="inline">init_fn</code>
is an initialization function which returns an initial step state and
<code class="inline">step_fn</code> is a supervised train step constructed from <code class="inline">model</code>, <code class="inline">loss</code>,
and <code class="inline">optimizer</code>.</p><p><code class="inline">model</code> must be an Axon struct, a valid defn container
of Axon structs, or a <code class="inline">{init_fn, apply_fn}</code>-tuple where <code class="inline">init_fn</code> is
an arity-0 function which initializes the model state and <code class="inline">apply_fn</code> is
an arity-2 function which applies the forward pass of the model.</p><p><code class="inline">loss</code> must be an atom which matches a function in <a href="Axon.Losses.html"><code class="inline">Axon.Losses</code></a>, a list
of <code class="inline">{loss, weight}</code> tuples representing a basic weighted loss function
for multi-output models, or an arity-2 function representing a custom loss
function.</p><p><code class="inline">optimizer</code> must be an atom matching the name of a valid optimizer in <a href="Axon.Optimizers.html"><code class="inline">Axon.Optimizers</code></a>,
or a <code class="inline">{init_fn, update_fn}</code> tuple where <code class="inline">init_fn</code> is an arity-1 function which
initializes the optimizer state from attached parameters and <code class="inline">update_fn</code> is an
arity-3 function which scales gradient updates with respect to input parameters,
optimizer state, and gradients. See <a href="Axon.Updates.html"><code class="inline">Axon.Updates</code></a> for more information on building
optimizers.</p>
  </section>
</section>
<section class="detail" id="trainer/3">

  <div class="detail-header">
    <a href="#trainer/3" class="detail-link" title="Link to this function">
      <span class="icon-link" aria-hidden="true"></span>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">trainer(model, loss, optimizer)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.1.0-dev/lib/axon/loop.ex#L508" class="view-source" rel="help" title="View Source">
       <span class="icon-code" aria-hidden="true"></span>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Creates a supervised training loop from a model, loss function,
and optimizer.</p><p>This function is useful for training models on most standard supervised
learning tasks. It assumes data consists of tuples of input-target pairs,
e.g. <code class="inline">[{x0, y0}, {x1, y1}, ..., {xN, yN}]</code> where <code class="inline">x0</code> and <code class="inline">y0</code> are batched
tensors or containers of batched tensors.</p><p>It defines an initialization function which first initializes model state
using the given model and then initializes optimizer state using the initial
model state. The step function uses a differentiable objective function
defined with respect to the model parameters, input data, and target data
using the given loss function. It then updates model parameters using the
given optimizer in order to minimize loss with respect to the model parameters.</p><p><code class="inline">model</code> must be an Axon struct, a valid defn container
of Axon structs, or a <code class="inline">{init_fn, apply_fn}</code>-tuple where <code class="inline">init_fn</code> is
an arity-0 function which initializes the model state and <code class="inline">apply_fn</code> is
an arity-2 function which applies the forward pass of the model.</p><p><code class="inline">loss</code> must be an atom which matches a function in <a href="Axon.Losses.html"><code class="inline">Axon.Losses</code></a>, a list
of <code class="inline">{loss, weight}</code> tuples representing a basic weighted loss function
for multi-output models, or an arity-2 function representing a custom loss
function.</p><p><code class="inline">optimizer</code> must be an atom matching the name of a valid optimizer in <a href="Axon.Optimizers.html"><code class="inline">Axon.Optimizers</code></a>,
or a <code class="inline">{init_fn, update_fn}</code> tuple where <code class="inline">init_fn</code> is an arity-1 function which
initializes the optimizer state from attached parameters and <code class="inline">update_fn</code> is an
arity-3 function which scales gradient updates with respect to input parameters,
optimizer state, and gradients. See <a href="Axon.Updates.html"><code class="inline">Axon.Updates</code></a> for more information on building
optimizers.</p><p>This function creates a step function which outputs a map consisting of the following
fields for <code class="inline">step_state</code>:</p><pre><code class="makeup elixir"><span class="p" data-group-id="1489876741-1">%{</span><span class="w">
  </span><span class="ss">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">tensor</span><span class="p" data-group-id="1489876741-2">(</span><span class="p" data-group-id="1489876741-2">)</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="1489876741-3">(</span><span class="n">tensor</span><span class="p" data-group-id="1489876741-4">(</span><span class="p" data-group-id="1489876741-4">)</span><span class="p" data-group-id="1489876741-3">)</span><span class="p">,</span><span class="w"> </span><span class="c1"># Model predictions for use in metrics</span><span class="w">
  </span><span class="ss">y_true</span><span class="p">:</span><span class="w"> </span><span class="n">tensor</span><span class="p" data-group-id="1489876741-5">(</span><span class="p" data-group-id="1489876741-5">)</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="1489876741-6">(</span><span class="n">tensor</span><span class="p" data-group-id="1489876741-7">(</span><span class="p" data-group-id="1489876741-7">)</span><span class="p" data-group-id="1489876741-6">)</span><span class="p">,</span><span class="w"> </span><span class="c1"># True labels for use in metrics</span><span class="w">
  </span><span class="ss">loss</span><span class="p">:</span><span class="w"> </span><span class="n">tensor</span><span class="p" data-group-id="1489876741-8">(</span><span class="p" data-group-id="1489876741-8">)</span><span class="p">,</span><span class="w"> </span><span class="c1"># Running average of loss over epoch</span><span class="w">
  </span><span class="ss">model_state</span><span class="p">:</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="1489876741-9">(</span><span class="n">tensor</span><span class="p" data-group-id="1489876741-10">(</span><span class="p" data-group-id="1489876741-10">)</span><span class="p" data-group-id="1489876741-9">)</span><span class="p">,</span><span class="w"> </span><span class="c1"># Model parameters and state</span><span class="w">
  </span><span class="ss">optimizer_state</span><span class="p">:</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="1489876741-11">(</span><span class="n">tensor</span><span class="p" data-group-id="1489876741-12">(</span><span class="p" data-group-id="1489876741-12">)</span><span class="p" data-group-id="1489876741-11">)</span><span class="w"> </span><span class="c1"># Optimizer state assosciated with each parameter</span><span class="w">
</span><span class="p" data-group-id="1489876741-1">}</span></code></pre><h2 id="trainer/3-examples" class="section-heading">
  <a href="#trainer/3-examples" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Examples
</h2>
<h3 id="trainer/3-basic-usage" class="section-heading">
  <a href="#trainer/3-basic-usage" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Basic usage
</h3>
<pre><code class="makeup elixir"><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Stream</span><span class="o">.</span><span class="n">zip</span><span class="p" data-group-id="8414472951-1">(</span><span class="n">input</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="p" data-group-id="8414472951-1">)</span><span class="w">

</span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">input</span><span class="p" data-group-id="8414472951-2">(</span><span class="p" data-group-id="8414472951-3">{</span><span class="no">nil</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p" data-group-id="8414472951-3">}</span><span class="p" data-group-id="8414472951-2">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">dense</span><span class="p" data-group-id="8414472951-4">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="ss">activation</span><span class="p">:</span><span class="w"> </span><span class="ss">:sigmoid</span><span class="p" data-group-id="8414472951-4">)</span><span class="w">

</span><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="8414472951-5">(</span><span class="ss">:binary_cross_entropy</span><span class="p">,</span><span class="w"> </span><span class="ss">:adam</span><span class="p" data-group-id="8414472951-5">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="8414472951-6">(</span><span class="n">data</span><span class="p" data-group-id="8414472951-6">)</span></code></pre><h3 id="trainer/3-customizing-optimizer" class="section-heading">
  <a href="#trainer/3-customizing-optimizer" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Customizing Optimizer
</h3>
<pre><code class="makeup elixir"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="4625709048-1">(</span><span class="ss">:binary_cross_entropy</span><span class="p">,</span><span class="w"> </span><span class="nc">Axon.Optimizers</span><span class="o">.</span><span class="n">adam</span><span class="p" data-group-id="4625709048-2">(</span><span class="mf">0.05</span><span class="p" data-group-id="4625709048-2">)</span><span class="p" data-group-id="4625709048-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="4625709048-3">(</span><span class="n">data</span><span class="p" data-group-id="4625709048-3">)</span></code></pre><h3 id="trainer/3-custom-loss" class="section-heading">
  <a href="#trainer/3-custom-loss" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Custom loss
</h3>
<pre><code class="makeup elixir"><span class="n">loss_fn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k" data-group-id="4139875595-1">fn</span><span class="w"> </span><span class="n">y_true</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">cos</span><span class="p" data-group-id="4139875595-2">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p" data-group-id="4139875595-2">)</span><span class="w"> </span><span class="k" data-group-id="4139875595-1">end</span><span class="w">

</span><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="4139875595-3">(</span><span class="n">loss_fn</span><span class="p">,</span><span class="w"> </span><span class="nc">Axon.Optimizers</span><span class="o">.</span><span class="n">rmsprop</span><span class="p" data-group-id="4139875595-4">(</span><span class="mf">0.01</span><span class="p" data-group-id="4139875595-4">)</span><span class="p" data-group-id="4139875595-3">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="4139875595-5">(</span><span class="n">data</span><span class="p" data-group-id="4139875595-5">)</span></code></pre><h3 id="trainer/3-multiple-objectives-with-multi-output-model" class="section-heading">
  <a href="#trainer/3-multiple-objectives-with-multi-output-model" class="hover-link"><span class="icon-link" aria-hidden="true"></span></a>
  Multiple objectives with multi-output model
</h3>
<pre><code class="makeup elixir"><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="0344961426-1">{</span><span class="nc">Axon</span><span class="o">.</span><span class="n">input</span><span class="p" data-group-id="0344961426-2">(</span><span class="p" data-group-id="0344961426-3">{</span><span class="no">nil</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p" data-group-id="0344961426-3">}</span><span class="p" data-group-id="0344961426-2">)</span><span class="p">,</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">input</span><span class="p" data-group-id="0344961426-4">(</span><span class="p" data-group-id="0344961426-5">{</span><span class="no">nil</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p" data-group-id="0344961426-5">}</span><span class="p" data-group-id="0344961426-4">)</span><span class="p" data-group-id="0344961426-1">}</span><span class="w">
</span><span class="n">loss_weights</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="0344961426-6">[</span><span class="ss">mean_squared_error</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="ss">mean_absolute_error</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="p" data-group-id="0344961426-6">]</span><span class="w">

</span><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="0344961426-7">(</span><span class="n">loss_weights</span><span class="p" data-group-id="0344961426-7">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="0344961426-8">(</span><span class="n">data</span><span class="p" data-group-id="0344961426-8">)</span></code></pre>
  </section>
</section>

    </div>
  </section>

      <footer class="footer">

        <p>
          <span class="line">
            Built using
            <a href="https://github.com/elixir-lang/ex_doc" title="ExDoc" target="_blank" rel="help noopener" translate="no">ExDoc</a> (v0.26.0) for the
            <a href="https://elixir-lang.org" title="Elixir" target="_blank" translate="no">Elixir programming language</a>.
          </span>
          <span class="line">
            Designed by
            <a href="https://twitter.com/dignifiedquire" target="_blank" rel="noopener" title="@dignifiedquire" translate="no">Friedel Ziegelmayer</a>.
          </span>
        </p>
        <p>

            <a href="api-reference.html" title="API reference" class="line footer-button">API Reference</a>

          <button class="line footer-button display-shortcuts-help">
            Display keyboard shortcuts
          </button>
          <button class="line footer-button display-quick-switch">
            Go to a HexDocs package
          </button>
          <button class="line footer-button display-settings">
            Settings
          </button>
        </p>
      </footer>
    </div>
  </div>
</section>
</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css" integrity="sha384-t5CR+zwDAROtph0PXGte6ia8heboACF9R5l/DiY+WZ3P2lxNgvJkQk5n7GPvLMYw" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js" integrity="sha384-FaFLTlohFghEIZkw6VGwmf9ISTubWAVYW8tG8+w2LAIftJEULZABrF9PPFv+tVkH" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js" integrity="sha384-bHBqxz8fokvgoJ/sc17HODNxa42TlaEhB+w8ZJXTc2nZf1VgEaFZeZvT4Mznfz0v" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

  </body>
</html>
