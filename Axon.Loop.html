<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="ExDoc v0.29.3">
    <meta name="project" content="Axon v0.5.1">

    <title>Axon.Loop â€” Axon v0.5.1</title>
    <link rel="stylesheet" href="dist/html-elixir-MB5C7R66.css" />


    <script src="dist/handlebars.runtime-NWIB6V2M.js"></script>
    <script src="dist/handlebars.templates-XRYTXUVD.js"></script>
    <script src="dist/sidebar_items-AF538DCA.js"></script>

      <script src="docs_config.js"></script>

    <script async src="dist/html-EHGDP2LQ.js"></script>


  </head>
  <body data-type="modules" class="page-module">
    <script>

      try {
        var settings = JSON.parse(localStorage.getItem('ex_doc:settings') || '{}');

        if (settings.theme === 'dark' ||
           ((settings.theme === 'system' || settings.theme == null) &&
             window.matchMedia('(prefers-color-scheme: dark)').matches)
           ) {
          document.body.classList.add('dark')
        }
      } catch (error) { }
    </script>

<div class="main">

<button class="sidebar-button sidebar-toggle" aria-label="toggle sidebar">
  <i class="ri-menu-line ri-lg" title="Collapse/expand sidebar"></i>
</button>

<section class="sidebar">
  <form class="sidebar-search" action="search.html">
    <button type="submit" class="search-button" aria-label="Submit Search">
      <i class="ri-search-2-line" aria-hidden="true" title="Submit search"></i>
    </button>
    <button type="button" tabindex="-1" class="search-close-button" aria-label="Cancel Search">
      <i class="ri-close-line ri-lg" aria-hidden="true" title="Cancel search"></i>
    </button>
    <label class="search-label">
      <p class="sr-only">Search</p>
      <input name="q" type="text" class="search-input" placeholder="Search..." aria-label="Input your search terms" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" />
    </label>
  </form>

  <div class="autocomplete">
    <div class="autocomplete-results">
    </div>
  </div>

  <div class="sidebar-header">

      <a href="Axon.html">
        <img src="assets/logo.png" alt="Axon" class="sidebar-projectImage">
      </a>

    <div class="sidebar-projectDetails">
      <a href="Axon.html" class="sidebar-projectName" translate="no">
Axon
      </a>
      <strong class="sidebar-projectVersion" translate="no">
        v0.5.1
      </strong>
    </div>
    <ul class="sidebar-listNav">
      <li><a id="extras-list-link" href="#full-list">Pages</a></li>

        <li><a id="modules-list-link" href="#full-list">Modules</a></li>


    </ul>
  </div>

  <div class="gradient"></div>
  <ul id="full-list"></ul>
</section>

<section class="content">
  <output role="status" id="toast"></output>
  <div class="content-outer">
    <div id="content" class="content-inner">

<h1>
<button class="icon-action display-settings">
  <i class="ri-settings-3-line"></i>
  <span class="sr-only">Settings</span>
</button>


    <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1" title="View Source" class="icon-action" rel="help">
      <i class="ri-code-s-slash-line" aria-hidden="true"></i>
      <span class="sr-only">View Source</span>
    </a>

  <span translate="no">Axon.Loop</span> 
  <small class="app-vsn" translate="no">(Axon v0.5.1)</small>

</h1>


  <section id="moduledoc">
<p>Abstraction for modeling a reduction of a dataset with an accumulated
state for a number of epochs.</p><p>Inspired heavily by <a href="https://pytorch.org/ignite/index.html">PyTorch Ignite</a>.</p><p>The main abstraction is the <code class="inline">%Axon.Loop{}</code> struct, which controls a nested
reduction of the form:</p><pre><code class="makeup elixir" translate="no"><span class="nc">Enum</span><span class="o">.</span><span class="n">reduce</span><span class="p" data-group-id="6476667106-1">(</span><span class="mi">1</span><span class="o">..</span><span class="n">max_epochs</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p">,</span><span class="w"> </span><span class="k" data-group-id="6476667106-2">fn</span><span class="w"> </span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
  </span><span class="nc">Enum</span><span class="o">.</span><span class="n">reduce</span><span class="p" data-group-id="6476667106-3">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">batch_step</span><span class="o">/</span><span class="mi">2</span><span class="p" data-group-id="6476667106-3">)</span><span class="w">
</span><span class="k" data-group-id="6476667106-2">end</span><span class="p" data-group-id="6476667106-1">)</span></code></pre><p><code class="inline">data</code> is assumed to be an <a href="https://hexdocs.pm/elixir/Enumerable.html"><code class="inline">Enumerable</code></a> or <a href="https://hexdocs.pm/elixir/Stream.html"><code class="inline">Stream</code></a> of input data which is
handled by a processing function, <code class="inline">batch_step</code>. The purpose of the loop
abstraction is to take away much of the boilerplate code used in solving machine
learning tasks. Tasks such as normalizing a dataset, hyperparameter optimization,
or training machine learning models boil down to writing one function:</p><pre><code class="makeup elixir" translate="no"><span class="kd">defn</span><span class="w"> </span><span class="nf">batch_step</span><span class="p" data-group-id="2290613805-1">(</span><span class="n">batch</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p" data-group-id="2290613805-1">)</span><span class="w"> </span><span class="k" data-group-id="2290613805-2">do</span><span class="w">
  </span><span class="c1"># ...do something with batch...</span><span class="w">
  </span><span class="n">updated_state</span><span class="w">
</span><span class="k" data-group-id="2290613805-2">end</span></code></pre><p>For tasks such as training a neural network, <code class="inline">state</code> will encapsulate things
such as model and optimizer state. For supervised learning tasks, <code class="inline">batch_step</code>
might look something like:</p><pre><code class="makeup elixir" translate="no"><span class="kd">defn</span><span class="w"> </span><span class="nf">batch_step</span><span class="p" data-group-id="4684305023-1">(</span><span class="p" data-group-id="4684305023-2">{</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p" data-group-id="4684305023-2">}</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p" data-group-id="4684305023-1">)</span><span class="w"> </span><span class="k" data-group-id="4684305023-3">do</span><span class="w">
  </span><span class="p" data-group-id="4684305023-4">%{</span><span class="ss">parameters</span><span class="p">:</span><span class="w"> </span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="ss">optimizer_state</span><span class="p">:</span><span class="w"> </span><span class="n">optim_state</span><span class="p" data-group-id="4684305023-4">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">state</span><span class="w">

  </span><span class="n">gradients</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">grad</span><span class="p" data-group-id="4684305023-5">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">objective_fn</span><span class="o">.</span><span class="p" data-group-id="4684305023-6">(</span><span class="ni">&amp;1</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p" data-group-id="4684305023-6">)</span><span class="p" data-group-id="4684305023-5">)</span><span class="w">
  </span><span class="p" data-group-id="4684305023-7">{</span><span class="n">updates</span><span class="p">,</span><span class="w"> </span><span class="n">new_optim_state</span><span class="p" data-group-id="4684305023-7">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">optimizer</span><span class="o">.</span><span class="p" data-group-id="4684305023-8">(</span><span class="n">optim_state</span><span class="p">,</span><span class="w"> </span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">gradients</span><span class="p" data-group-id="4684305023-8">)</span><span class="w">

  </span><span class="n">new_params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">apply_updates</span><span class="p" data-group-id="4684305023-9">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">updates</span><span class="p" data-group-id="4684305023-9">)</span><span class="w">

  </span><span class="p" data-group-id="4684305023-10">%{</span><span class="ss">parameters</span><span class="p">:</span><span class="w"> </span><span class="n">new_params</span><span class="p">,</span><span class="w"> </span><span class="ss">optimizer_state</span><span class="p">:</span><span class="w"> </span><span class="n">optim_state</span><span class="p" data-group-id="4684305023-10">}</span><span class="w">
</span><span class="k" data-group-id="4684305023-3">end</span></code></pre><p><code class="inline">batch_step</code> takes a batch of <code class="inline">{input, target}</code> pairs and the current state,
and updates the model parameters based on the gradients received from some arbitrary
objective function. This function will run in a nested loop, iterating over the entire
dataset for <code class="inline">N</code> epochs before finally returning the trained model state. By defining
1 function, we've created a training loop that works for most machine learning models.</p><p>In actuality, the loop abstraction accumulates a struct, <code class="inline">%Axon.Loop.State{}</code>, which looks
like (assuming <code class="inline">container</code> is a generic Elixir container of tensors, e.g. map, tuple, etc.):</p><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="6231311372-1">%</span><span class="nc" data-group-id="6231311372-1">Axon.Loop.State</span><span class="p" data-group-id="6231311372-1">{</span><span class="w">
  </span><span class="ss">epoch</span><span class="p">:</span><span class="w"> </span><span class="n">integer</span><span class="p" data-group-id="6231311372-2">(</span><span class="p" data-group-id="6231311372-2">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">max_epoch</span><span class="p">:</span><span class="w"> </span><span class="n">integer</span><span class="p" data-group-id="6231311372-3">(</span><span class="p" data-group-id="6231311372-3">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">iteration</span><span class="p">:</span><span class="w"> </span><span class="n">integer</span><span class="p" data-group-id="6231311372-4">(</span><span class="p" data-group-id="6231311372-4">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">max_iteration</span><span class="p">:</span><span class="w"> </span><span class="n">integer</span><span class="p" data-group-id="6231311372-5">(</span><span class="p" data-group-id="6231311372-5">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">metrics</span><span class="p">:</span><span class="w"> </span><span class="n">map</span><span class="p" data-group-id="6231311372-6">(</span><span class="n">string</span><span class="p" data-group-id="6231311372-7">(</span><span class="p" data-group-id="6231311372-7">)</span><span class="p">,</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="6231311372-8">(</span><span class="p" data-group-id="6231311372-8">)</span><span class="p" data-group-id="6231311372-6">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">times</span><span class="p">:</span><span class="w"> </span><span class="n">map</span><span class="p" data-group-id="6231311372-9">(</span><span class="n">integer</span><span class="p" data-group-id="6231311372-10">(</span><span class="p" data-group-id="6231311372-10">)</span><span class="p">,</span><span class="w"> </span><span class="n">integer</span><span class="p" data-group-id="6231311372-11">(</span><span class="p" data-group-id="6231311372-11">)</span><span class="p" data-group-id="6231311372-9">)</span><span class="p">,</span><span class="w">
  </span><span class="ss">step_state</span><span class="p">:</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="6231311372-12">(</span><span class="p" data-group-id="6231311372-12">)</span><span class="w">
</span><span class="p" data-group-id="6231311372-1">}</span></code></pre><p><code class="inline">batch_step</code> takes in the batch and the step state field and returns a <code class="inline">step_state</code>,
which is a generic container of state accumulated at each iteration. The rest of the fields
in the state struct are updated automatically behind the scenes.</p><p>The loop must start from some initial step state, thus most tasks must also provide
an additional initialization function to provide some starting point for the step
state. For machine learning tasks, the initialization function will return things like
initial model parameters and optimizer state.</p><p>Typically, the final output of the loop is the accumulated final state; however, you
may optionally apply an output transform to extract specific values at the end of the
loop. For example, <a href="#trainer/4"><code class="inline">Axon.Loop.trainer/4</code></a> by default extracts trained model state:</p><pre><code class="makeup elixir" translate="no"><span class="n">output_transform</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k" data-group-id="2686771688-1">fn</span><span class="w"> </span><span class="n">state</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
  </span><span class="n">state</span><span class="o">.</span><span class="n">step_state</span><span class="p" data-group-id="2686771688-2">[</span><span class="ss">:model_state</span><span class="p" data-group-id="2686771688-2">]</span><span class="w">
</span><span class="k" data-group-id="2686771688-1">end</span></code></pre><h2 id="module-initialize-and-step" class="section-heading">
  <a href="#module-initialize-and-step" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">initialize-and-step</p>
  </a>
  Initialize and Step
</h2>
<p>The core of the Axon loop are the init and step functions. The initialization is an
arity-0 function which provides an initial step state:</p><pre><code class="makeup elixir" translate="no"><span class="n">init</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k" data-group-id="6197156754-1">fn</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
  </span><span class="p" data-group-id="6197156754-2">%{</span><span class="ss">params</span><span class="p">:</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">init</span><span class="p" data-group-id="6197156754-3">(</span><span class="n">model</span><span class="p" data-group-id="6197156754-3">)</span><span class="p" data-group-id="6197156754-2">}</span><span class="w">
</span><span class="k" data-group-id="6197156754-1">end</span></code></pre><p>While the step function is the <code class="inline">batch_step</code> function mentioned earlier:</p><pre><code class="makeup elixir" translate="no"><span class="n">step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k" data-group-id="2038007762-1">fn</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
  </span><span class="n">new_state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="c1"># ...do something...</span><span class="w">
  </span><span class="n">new_state</span><span class="w">
</span><span class="k" data-group-id="2038007762-1">end</span></code></pre><p>Note that any optimization and training anonymous functions that need to be used in the
<code class="inline">batch_step</code> function can be passed as extra arguments. For example:</p><pre><code class="makeup elixir" translate="no"><span class="n">step_with_training_arguments</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k" data-group-id="1796740436-1">fn</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p">,</span><span class="w"> </span><span class="n">optimizer_update_fn</span><span class="p">,</span><span class="w"> </span><span class="n">state_update_fn</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
  </span><span class="c1"># ...do something...</span><span class="w">
</span><span class="k" data-group-id="1796740436-1">end</span><span class="w">

</span><span class="n">step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="p" data-group-id="1796740436-2">(</span><span class="n">step_with_training_arguments</span><span class="o">.</span><span class="p" data-group-id="1796740436-3">(</span><span class="ni">&amp;1</span><span class="p">,</span><span class="w"> </span><span class="ni">&amp;2</span><span class="p">,</span><span class="w"> </span><span class="n">actual_optimizer_update_fn</span><span class="p">,</span><span class="w"> </span><span class="n">actual_state_update_fn</span><span class="p" data-group-id="1796740436-3">)</span><span class="p" data-group-id="1796740436-2">)</span></code></pre><h2 id="module-metrics" class="section-heading">
  <a href="#module-metrics" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">metrics</p>
  </a>
  Metrics
</h2>
<p>Often times you want to compute metrics associated with your training iterations.
To accomplish this, you can attach metrics to each <a href="Axon.Loop.html#content"><code class="inline">Axon.Loop</code></a>. Assuming a <code class="inline">batch_step</code>
function which looks like:</p><pre><code class="makeup elixir" translate="no"><span class="kd">defn</span><span class="w"> </span><span class="nf">batch_step</span><span class="p" data-group-id="9710663306-1">(</span><span class="p" data-group-id="9710663306-2">{</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p" data-group-id="9710663306-2">}</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p" data-group-id="9710663306-1">)</span><span class="w"> </span><span class="k" data-group-id="9710663306-3">do</span><span class="w">
  </span><span class="p" data-group-id="9710663306-4">%{</span><span class="ss">parameters</span><span class="p">:</span><span class="w"> </span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="ss">optimizer_state</span><span class="p">:</span><span class="w"> </span><span class="n">optim_state</span><span class="p" data-group-id="9710663306-4">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">state</span><span class="w">

  </span><span class="n">gradients</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">grad</span><span class="p" data-group-id="9710663306-5">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">objective_fn</span><span class="o">.</span><span class="p" data-group-id="9710663306-6">(</span><span class="ni">&amp;1</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p" data-group-id="9710663306-6">)</span><span class="p" data-group-id="9710663306-5">)</span><span class="w">
  </span><span class="p" data-group-id="9710663306-7">{</span><span class="n">updates</span><span class="p">,</span><span class="w"> </span><span class="n">new_optim_state</span><span class="p" data-group-id="9710663306-7">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">optimizer</span><span class="o">.</span><span class="p" data-group-id="9710663306-8">(</span><span class="n">optim_state</span><span class="p">,</span><span class="w"> </span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">gradients</span><span class="p" data-group-id="9710663306-8">)</span><span class="w">

  </span><span class="n">new_params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">apply_updates</span><span class="p" data-group-id="9710663306-9">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">updates</span><span class="p" data-group-id="9710663306-9">)</span><span class="w">

  </span><span class="c1"># Shown for simplicity, you can optimize this by calculating preds</span><span class="w">
  </span><span class="c1"># along with the gradient calculation</span><span class="w">
  </span><span class="n">preds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_fn</span><span class="o">.</span><span class="p" data-group-id="9710663306-10">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p" data-group-id="9710663306-10">)</span><span class="w">

  </span><span class="p" data-group-id="9710663306-11">%{</span><span class="w">
    </span><span class="ss">y_true</span><span class="p">:</span><span class="w"> </span><span class="n">targets</span><span class="p">,</span><span class="w">
    </span><span class="ss">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">preds</span><span class="p">,</span><span class="w">
    </span><span class="ss">parameters</span><span class="p">:</span><span class="w"> </span><span class="n">new_params</span><span class="p">,</span><span class="w">
    </span><span class="ss">optimizer_state</span><span class="p">:</span><span class="w"> </span><span class="n">optim_state</span><span class="w">
  </span><span class="p" data-group-id="9710663306-11">}</span><span class="w">
</span><span class="k" data-group-id="9710663306-3">end</span></code></pre><p>You can attach metrics to this by using <a href="#metric/4"><code class="inline">Axon.Loop.metric/4</code></a>:</p><pre><code class="makeup elixir" translate="no"><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">loop</span><span class="p" data-group-id="6217881463-1">(</span><span class="o">&amp;</span><span class="n">batch_step</span><span class="o">/</span><span class="mi">2</span><span class="p" data-group-id="6217881463-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="6217881463-2">(</span><span class="s">&quot;Accuracy&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">:accuracy</span><span class="p">,</span><span class="w"> </span><span class="k" data-group-id="6217881463-3">fn</span><span class="w"> </span><span class="p" data-group-id="6217881463-4">%{</span><span class="ss">y_true</span><span class="p">:</span><span class="w"> </span><span class="n">y_</span><span class="p">,</span><span class="w"> </span><span class="ss">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">y</span><span class="p" data-group-id="6217881463-4">}</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p" data-group-id="6217881463-5">[</span><span class="n">y_</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p" data-group-id="6217881463-5">]</span><span class="w"> </span><span class="k" data-group-id="6217881463-3">end</span><span class="p" data-group-id="6217881463-2">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="6217881463-6">(</span><span class="n">data</span><span class="p" data-group-id="6217881463-6">)</span></code></pre><p>Because metrics work directly on <code class="inline">step_state</code>, you typically need to provide an output
transform to indicate which values should be passed to your metric function. By default,
Axon assumes a supervised training task with the fields <code class="inline">:y_true</code> and <code class="inline">:y_pred</code> present
in the step state. See <a href="#metric/4"><code class="inline">Axon.Loop.metric/4</code></a> for more information.</p><p>Metrics will be tracked in the loop state using the user-provided key. Metrics integrate
seamlessly with the supervised metrics defined in <a href="Axon.Metrics.html"><code class="inline">Axon.Metrics</code></a>. You can also use metrics
to keep running averages of some values in the original dataset.</p><h2 id="module-events-and-handlers" class="section-heading">
  <a href="#module-events-and-handlers" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">events-and-handlers</p>
  </a>
  Events and Handlers
</h2>
<p>You can instrument several points in the loop using event handlers. By default, several events
are fired when running a loop:</p><pre><code class="makeup elixir" translate="no"><span class="n">events</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="3948955891-1">[</span><span class="w">
  </span><span class="ss">:started</span><span class="p">,</span><span class="w">             </span><span class="c1"># After loop state initialization</span><span class="w">
  </span><span class="ss">:epoch_started</span><span class="p">,</span><span class="w">       </span><span class="c1"># On epoch start</span><span class="w">
  </span><span class="ss">:iteration_started</span><span class="p">,</span><span class="w">   </span><span class="c1"># On iteration start</span><span class="w">
  </span><span class="ss">:iteration_completed</span><span class="p">,</span><span class="w"> </span><span class="c1"># On iteration complete</span><span class="w">
  </span><span class="ss">:epoch_completed</span><span class="p">,</span><span class="w">     </span><span class="c1"># On epoch complete</span><span class="w">
  </span><span class="ss">:epoch_halted</span><span class="p">,</span><span class="w">        </span><span class="c1"># On epoch halt, if early halted</span><span class="w">
</span><span class="p" data-group-id="3948955891-1">]</span></code></pre><p>You can attach event handlers to events using <a href="#handle_event/4"><code class="inline">Axon.Loop.handle_event/4</code></a>:</p><pre><code class="makeup elixir" translate="no"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">handle_event</span><span class="p" data-group-id="0613820874-1">(</span><span class="ss">:iteration_completed</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">log_metrics</span><span class="o">/</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="ss">every</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p" data-group-id="0613820874-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="0613820874-2">(</span><span class="n">data</span><span class="p" data-group-id="0613820874-2">)</span></code></pre><p>The above will trigger <code class="inline">log_metrics/1</code> every 100 times the <code class="inline">:iteration_completed</code> event
is fired. Event handlers must return a tuple <code class="inline">{status, state}</code>, where <code class="inline">status</code> is an
atom with one of the following values:</p><pre><code class="makeup elixir" translate="no"><span class="ss">:continue</span><span class="w">   </span><span class="c1"># Continue epoch, continue looping</span><span class="w">
</span><span class="ss">:halt_epoch</span><span class="w"> </span><span class="c1"># Halt the epoch, continue looping</span><span class="w">
</span><span class="ss">:halt_loop</span><span class="w">  </span><span class="c1"># Halt looping</span></code></pre><p>And <code class="inline">state</code> is an updated <a href="Axon.Loop.State.html"><code class="inline">Axon.Loop.State</code></a> struct. Handler functions take as input
the current loop state.</p><p>It's important to note that event handlers are triggered in the order they are attached
to the loop. If you have two handlers on the same event, they will trigger in order:</p><pre><code class="makeup elixir" translate="no"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">handle_event</span><span class="p" data-group-id="2713160190-1">(</span><span class="ss">:epoch_completed</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">normalize_state</span><span class="o">/</span><span class="mi">1</span><span class="p" data-group-id="2713160190-1">)</span><span class="w"> </span><span class="c1"># Runs first</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">handle_event</span><span class="p" data-group-id="2713160190-2">(</span><span class="ss">:epoch_completed</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">log_state</span><span class="o">/</span><span class="mi">1</span><span class="p" data-group-id="2713160190-2">)</span><span class="w"> </span><span class="c1"># Runs second</span></code></pre><p>You may provide filters to filter when event handlers trigger. See <a href="#handle_event/4"><code class="inline">Axon.Loop.handle_event/4</code></a>
for more details on valid filters.</p><h2 id="module-factories" class="section-heading">
  <a href="#module-factories" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">factories</p>
  </a>
  Factories
</h2>
<p>Axon loops are typically created from one of the factory functions provided in this
module:</p><pre><code class="makeup elixir" translate="no"><span class="o">*</span><span class="w"> </span><span class="err">`</span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">loop</span><span class="o">/</span><span class="mi">3</span><span class="err">`</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nc">Creates</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">loop</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="n">function</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">optional</span><span class="w"> </span><span class="n">initialization</span><span class="w">
</span><span class="n">functions</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="n">transform</span><span class="w"> </span><span class="n">functions</span><span class="o">.</span><span class="w">

</span><span class="o">*</span><span class="w"> </span><span class="err">`</span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="o">/</span><span class="mi">3</span><span class="err">`</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nc">Creates</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">supervised</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">loop</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w">
</span><span class="n">optimizer</span><span class="o">.</span><span class="w">

</span><span class="o">*</span><span class="w"> </span><span class="err">`</span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">evaluator</span><span class="o">/</span><span class="mi">1</span><span class="err">`</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nc">Creates</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">supervised</span><span class="w"> </span><span class="n">evaluator</span><span class="w"> </span><span class="n">loop</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="n">model</span><span class="o">.</span></code></pre><h2 id="module-running-loops" class="section-heading">
  <a href="#module-running-loops" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">running-loops</p>
  </a>
  Running loops
</h2>
<p>In order to execute a loop, you should use <a href="#run/3"><code class="inline">Axon.Loop.run/3</code></a>:</p><pre><code class="makeup elixir" translate="no"><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="1154066963-1">(</span><span class="n">loop</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="ss">epochs</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="p" data-group-id="1154066963-1">)</span></code></pre><h2 id="module-resuming-loops" class="section-heading">
  <a href="#module-resuming-loops" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">resuming-loops</p>
  </a>
  Resuming loops
</h2>
<p>At times you may want to resume a loop from some previous state. You can accomplish this
with <a href="#from_state/2"><code class="inline">Axon.Loop.from_state/2</code></a>:</p><pre><code class="makeup elixir" translate="no"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">from_state</span><span class="p" data-group-id="3542029542-1">(</span><span class="n">state</span><span class="p" data-group-id="3542029542-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="3542029542-2">(</span><span class="n">data</span><span class="p" data-group-id="3542029542-2">)</span></code></pre>
  </section>


  <section id="summary" class="details-list">
    <h1 class="section-heading">
      <a class="hover-link" href="#summary">
        <i class="ri-link-m" aria-hidden="true"></i>
        <span class="sr-only">Link to this section</span>
      </a>
      Summary
    </h1>
<div class="summary-functions summary">
  <h2>
    <a href="#functions">Functions</a>
  </h2>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#checkpoint/2" translate="no">checkpoint(loop, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adds a handler function which saves loop checkpoints on a given
event, optionally with metric-based criteria.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#deserialize_state/2" translate="no">deserialize_state(serialized, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Deserializes loop state from a binary.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#early_stop/3" translate="no">early_stop(loop, monitor, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adds a handler function which halts a loop if the given
metric does not improve between events.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#eval_step/1" translate="no">eval_step(model)</a>

      </div>

        <div class="summary-synopsis"><p>Creates a supervised evaluation step from a model and model state.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#evaluator/1" translate="no">evaluator(model)</a>

      </div>

        <div class="summary-synopsis"><p>Creates a supervised evaluator from a model.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#from_state/2" translate="no">from_state(loop, state)</a>

      </div>

        <div class="summary-synopsis"><p>Attaches <code class="inline">state</code> to the given loop in order to resume looping
from a previous state.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#handle_event/4" translate="no">handle_event(loop, event, handler, filter \\ :always)</a>

      </div>

        <div class="summary-synopsis"><p>Adds a handler function to the loop which will be triggered on <code class="inline">event</code>
with an optional filter.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#kino_vega_lite_plot/4" translate="no">kino_vega_lite_plot(loop, plot, metric, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adds a handler function which updates a <a href="https://hexdocs.pm/kino_vega_lite/0.1.8/Kino.VegaLite.html"><code class="inline">Kino.VegaLite</code></a> plot.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#log/3" translate="no">log(loop, message_fn, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adds a handler function which logs the given message produced
by <code class="inline">message_fn</code> to the given IO device every <code class="inline">event</code> satisfying
<code class="inline">filter</code>.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#loop/3" translate="no">loop(step_fn, init_fn \\ &amp;default_init/2, output_transform \\ &amp; &amp;1)</a>

      </div>

        <div class="summary-synopsis"><p>Creates a loop from <code class="inline">step_fn</code>, an optional <code class="inline">init_fn</code>, and an
optional <code class="inline">output_transform</code>.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#metric/5" translate="no">metric(loop, metric, name \\ nil, accumulate \\ :running_average, transform_or_fields \\ [:y_true, :y_pred])</a>

      </div>

        <div class="summary-synopsis"><p>Adds a metric of the given name to the loop.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#monitor/5" translate="no">monitor(loop, metric, fun, name, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adds a handler function which monitors the given metric
and fires some action when the given metric meets some
criteria.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#reduce_lr_on_plateau/3" translate="no">reduce_lr_on_plateau(loop, monitor, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adds a handler function which reduces the learning rate by
the given factor if the given metric does not improve between
events.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#run/4" translate="no">run(loop, data, init_state \\ %{}, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Runs the given loop on data with the given options.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#serialize_state/2" translate="no">serialize_state(state, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Serializes loop state to a binary for saving and loading
loop from previous states.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#train_step/4" translate="no">train_step(model, loss, optimizer, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Creates a supervised train step from a model, loss function, and
optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#trainer/4" translate="no">trainer(model, loss, optimizer, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Creates a supervised training loop from a model, loss function,
and optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#validate/4" translate="no">validate(loop, model, validation_data, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adds a handler function which tests the performance of <code class="inline">model</code>
against the given validation set.</p></div>

    </div>

</div>

  </section>


  <section id="functions" class="details-list">
    <h1 class="section-heading">
      <a class="hover-link" href="#functions">
        <i class="ri-link-m" aria-hidden="true"></i>
        <span class="sr-only">Link to this section</span>
      </a>
Functions
    </h1>
    <div class="functions-list">
<section class="detail" id="checkpoint/2">

    <span id="checkpoint/1"></span>

  <div class="detail-header">
    <a href="#checkpoint/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">checkpoint(loop, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1257" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a handler function which saves loop checkpoints on a given
event, optionally with metric-based criteria.</p><p>By default, loop checkpoints will be saved at the end of every
epoch in the current working directory under the <code class="inline">checkpoint/</code>
path. Checkpoints are serialized representations of loop state
obtained from <a href="#serialize_state/2"><code class="inline">Axon.Loop.serialize_state/2</code></a>. Serialization
options will be forwarded to <a href="#serialize_state/2"><code class="inline">Axon.Loop.serialize_state/2</code></a>.</p><p>You can customize checkpoint events by passing <code class="inline">:event</code> and <code class="inline">:filter</code>
options:</p><pre><code class="makeup elixir" translate="no"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">checkpoint</span><span class="p" data-group-id="3122463066-1">(</span><span class="ss">event</span><span class="p">:</span><span class="w"> </span><span class="ss">:iteration_completed</span><span class="p">,</span><span class="w"> </span><span class="ss">filter</span><span class="p">:</span><span class="w"> </span><span class="p" data-group-id="3122463066-2">[</span><span class="ss">every</span><span class="p">:</span><span class="w"> </span><span class="mi">50</span><span class="p" data-group-id="3122463066-2">]</span><span class="p" data-group-id="3122463066-1">)</span></code></pre><p>Checkpoints are saved under the <code class="inline">checkpoint/</code> directory with a pattern
of <code class="inline">checkpoint_{epoch}.ckpt</code>. You can customize the path and pattern
with the <code class="inline">:path</code> and <code class="inline">:file_pattern</code> options:</p><pre><code class="makeup elixir" translate="no"><span class="n">my_file_pattern</span><span class="w"> </span><span class="o">=</span><span class="w">
  </span><span class="k" data-group-id="6116618249-1">fn</span><span class="w"> </span><span class="p" data-group-id="6116618249-2">%</span><span class="nc" data-group-id="6116618249-2">Axon.Loop.State</span><span class="p" data-group-id="6116618249-2">{</span><span class="ss">epoch</span><span class="p">:</span><span class="w"> </span><span class="n">epoch</span><span class="p">,</span><span class="w"> </span><span class="ss">iteration</span><span class="p">:</span><span class="w"> </span><span class="n">iter</span><span class="p" data-group-id="6116618249-2">}</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
    </span><span class="s">&quot;checkpoint_</span><span class="si" data-group-id="6116618249-3">#{</span><span class="n">epoch</span><span class="si" data-group-id="6116618249-3">}</span><span class="s">_</span><span class="si" data-group-id="6116618249-4">#{</span><span class="n">iter</span><span class="si" data-group-id="6116618249-4">}</span><span class="s">&quot;</span><span class="w">
  </span><span class="k" data-group-id="6116618249-1">end</span><span class="w">

</span><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">checkpoint</span><span class="p" data-group-id="6116618249-5">(</span><span class="ss">path</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;my_checkpoints&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">file_pattern</span><span class="p">:</span><span class="w"> </span><span class="n">my_file_pattern</span><span class="p" data-group-id="6116618249-5">)</span></code></pre><p>If you'd like to only save checkpoints based on some metric criteria,
you can specify the <code class="inline">:criteria</code> option. <code class="inline">:criteria</code> must be a valid key
in metrics:</p><pre><code class="makeup elixir" translate="no"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">checkpoint</span><span class="p" data-group-id="6542004849-1">(</span><span class="ss">criteria</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;validation_loss&quot;</span><span class="p" data-group-id="6542004849-1">)</span></code></pre><p>The default criteria mode is <code class="inline">:min</code>, meaning the min score metric will
be considered &quot;best&quot; when deciding to save on a given event. Valid modes
are <code class="inline">:min</code> and <code class="inline">:max</code>:</p><pre><code class="makeup elixir" translate="no"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">checkpoint</span><span class="p" data-group-id="2635266061-1">(</span><span class="ss">criteria</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;validation_accuracy&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">mode</span><span class="p">:</span><span class="w"> </span><span class="ss">:max</span><span class="p" data-group-id="2635266061-1">)</span></code></pre><h2 id="checkpoint/2-options" class="section-heading">
  <a href="#checkpoint/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><p><code class="inline">:event</code> - event to fire handler on. Defaults to <code class="inline">:epoch_completed</code>.</p></li><li><p><code class="inline">:filter</code> - event filter to attach to handler. Defaults to <code class="inline">:always</code>.</p></li><li><p><code class="inline">:patience</code> - number of given events to wait for improvement. Defaults
to <code class="inline">3</code>.</p></li><li><p><code class="inline">:mode</code> - whether given metric is being minimized or maximized. One of
<code class="inline">:min</code>, <code class="inline">:max</code> or an arity-1 function which returns <code class="inline">true</code> or <code class="inline">false</code>.
Defaults to <code class="inline">:min</code>.</p></li><li><p><code class="inline">:path</code> - path to directory to save checkpoints. Defaults to <code class="inline">checkpoint</code></p></li><li><p><code class="inline">:file_pattern</code> - arity-1 function which returns a string file pattern
based on the current loop state. Defaults to saving checkpoints to files
<code class="inline">checkpoint_#{epoch}_#{iteration}.ckpt</code>.</p></li></ul>
  </section>
</section>
<section class="detail" id="deserialize_state/2">

    <span id="deserialize_state/1"></span>

  <div class="detail-header">
    <a href="#deserialize_state/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">deserialize_state(serialized, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1545" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Deserializes loop state from a binary.</p><p>It is the opposite of <a href="#serialize_state/2"><code class="inline">Axon.Loop.serialize_state/2</code></a>.</p><p>By default, the step state is deserialized using <code class="inline">Nx.deserialize.2</code>;
however, this behavior can be changed if step state is an application
specific container. For example, if you introduce your own data
structure into step_state and you customized the serialization logic,
<a href="https://hexdocs.pm/nx/0.5.3/Nx.html#deserialize/2"><code class="inline">Nx.deserialize/2</code></a> will not be sufficient for deserialization. - you
must pass custom logic with <code class="inline">:deserialize_step_state</code>.</p>
  </section>
</section>
<section class="detail" id="early_stop/3">

    <span id="early_stop/2"></span>

  <div class="detail-header">
    <a href="#early_stop/3" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">early_stop(loop, monitor, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1324" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a handler function which halts a loop if the given
metric does not improve between events.</p><p>By default, this will run after each epoch and track the
improvement of a given metric.</p><p>You must specify a metric to monitor and the metric must
be present in the loop state. Typically, this will be
a validation metric:</p><pre><code class="makeup elixir" translate="no"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="6858983123-1">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">optim</span><span class="p" data-group-id="6858983123-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="6858983123-2">(</span><span class="ss">:accuracy</span><span class="p" data-group-id="6858983123-2">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">validate</span><span class="p" data-group-id="6858983123-3">(</span><span class="n">val_data</span><span class="p" data-group-id="6858983123-3">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">early_stop</span><span class="p" data-group-id="6858983123-4">(</span><span class="s">&quot;validation_accuracy&quot;</span><span class="p" data-group-id="6858983123-4">)</span></code></pre><p>It's important to remember that handlers are executed in the
order they are added to the loop. For example, if you'd like
to checkpoint a loop after every epoch and use early stopping,
most likely you want to add the checkpoint handler before
the early stopping handler:</p><pre><code class="makeup elixir" translate="no"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="5263621599-1">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">optim</span><span class="p" data-group-id="5263621599-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="5263621599-2">(</span><span class="ss">:accuracy</span><span class="p" data-group-id="5263621599-2">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">checkpoint</span><span class="p" data-group-id="5263621599-3">(</span><span class="p" data-group-id="5263621599-3">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">early_stop</span><span class="p" data-group-id="5263621599-4">(</span><span class="s">&quot;accuracy&quot;</span><span class="p" data-group-id="5263621599-4">)</span></code></pre><p>That will ensure checkpoint is always fired, even if the loop
exited early.</p>
  </section>
</section>
<section class="detail" id="eval_step/1">

  <div class="detail-header">
    <a href="#eval_step/1" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">eval_step(model)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L513" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Creates a supervised evaluation step from a model and model state.</p><p>This function is intended for more fine-grained control over the loop
creation process. It returns a tuple of <code class="inline">{init_fn, step_fn}</code> where
<code class="inline">init_fn</code> returns an initial step state and <code class="inline">step_fn</code> performs a
single evaluation step.</p>
  </section>
</section>
<section class="detail" id="evaluator/1">

  <div class="detail-header">
    <a href="#evaluator/1" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">evaluator(model)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L795" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Creates a supervised evaluator from a model.</p><p>An evaluator can be used for things such as testing and validation of models
after or during training. It assumes <code class="inline">model</code> is an Axon struct, container of
structs, or a tuple of <code class="inline">init</code> / <code class="inline">apply</code> functions. <code class="inline">model_state</code> must be a
container usable from within <code class="inline">model</code>.</p><p>The evaluator returns a step state of the form:</p><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="4874608456-1">%{</span><span class="w">
  </span><span class="ss">y_true</span><span class="p">:</span><span class="w"> </span><span class="n">labels</span><span class="p">,</span><span class="w">
  </span><span class="ss">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">predictions</span><span class="w">
</span><span class="p" data-group-id="4874608456-1">}</span></code></pre><p>Such that you can attach any number of supervised metrics to the evaluation
loop:</p><pre><code class="makeup elixir" translate="no"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">evaluator</span><span class="p" data-group-id="6746690459-1">(</span><span class="p" data-group-id="6746690459-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="6746690459-2">(</span><span class="s">&quot;Accuracy&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">:accuracy</span><span class="p" data-group-id="6746690459-2">)</span></code></pre><p>You must pass a compatible trained model state to <a href="#run/4"><code class="inline">Axon.Loop.run/4</code></a> when using
supervised evaluation loops. For example, if you've binded the result of a training
run to <code class="inline">trained_model_state</code>, you can run the trained model through an evaluation
run like this:</p><pre><code class="makeup elixir" translate="no"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">evaluator</span><span class="p" data-group-id="3927323013-1">(</span><span class="p" data-group-id="3927323013-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="3927323013-2">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">trained_model_state</span><span class="p">,</span><span class="w"> </span><span class="ss">compiler</span><span class="p">:</span><span class="w"> </span><span class="nc">EXLA</span><span class="p" data-group-id="3927323013-2">)</span></code></pre><p>This function applies an output transform which returns the map of metrics accumulated
over the given loop.</p>
  </section>
</section>
<section class="detail" id="from_state/2">

  <div class="detail-header">
    <a href="#from_state/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">from_state(loop, state)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1503" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Attaches <code class="inline">state</code> to the given loop in order to resume looping
from a previous state.</p><p>It's important to note that a loop's attached state takes precedence
over defined initialization functions. Given initialization function:</p><pre><code class="makeup elixir" translate="no"><span class="kd">defn</span><span class="w"> </span><span class="nf">init_state</span><span class="p" data-group-id="2004395997-1">(</span><span class="p" data-group-id="2004395997-1">)</span><span class="p">,</span><span class="w"> </span><span class="ss">do</span><span class="p">:</span><span class="w"> </span><span class="p" data-group-id="2004395997-2">%{</span><span class="ss">foo</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="ss">bar</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p" data-group-id="2004395997-2">}</span></code></pre><p>And an attached state:</p><pre><code class="makeup elixir" translate="no"><span class="n">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="2544749913-1">%</span><span class="nc" data-group-id="2544749913-1">State</span><span class="p" data-group-id="2544749913-1">{</span><span class="ss">step_state</span><span class="p">:</span><span class="w"> </span><span class="p" data-group-id="2544749913-2">%{</span><span class="ss">foo</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="ss">bar</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p" data-group-id="2544749913-2">}</span><span class="p" data-group-id="2544749913-1">}</span></code></pre><p><code class="inline">init_state/0</code> will never execute, and instead the initial step state
of <code class="inline">%{foo: 2, bar: 3}</code> will be used.</p>
  </section>
</section>
<section class="detail" id="handle_event/4">

    <span id="handle_event/3"></span>

  <div class="detail-header">
    <a href="#handle_event/4" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">handle_event(loop, event, handler, filter \\ :always)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L941" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a handler function to the loop which will be triggered on <code class="inline">event</code>
with an optional filter.</p><p>Events take place at different points during loop execution. The default
events are:</p><pre><code class="makeup elixir" translate="no"><span class="n">events</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="6871326781-1">[</span><span class="w">
  </span><span class="ss">:started</span><span class="p">,</span><span class="w">             </span><span class="c1"># After loop state initialization</span><span class="w">
  </span><span class="ss">:epoch_started</span><span class="p">,</span><span class="w">       </span><span class="c1"># On epoch start</span><span class="w">
  </span><span class="ss">:iteration_started</span><span class="p">,</span><span class="w">   </span><span class="c1"># On iteration start</span><span class="w">
  </span><span class="ss">:iteration_completed</span><span class="p">,</span><span class="w"> </span><span class="c1"># On iteration complete</span><span class="w">
  </span><span class="ss">:epoch_completed</span><span class="p">,</span><span class="w">     </span><span class="c1"># On epoch complete</span><span class="w">
  </span><span class="ss">:epoch_halted</span><span class="p">,</span><span class="w">        </span><span class="c1"># On epoch halt, if early halted</span><span class="w">
</span><span class="p" data-group-id="6871326781-1">]</span></code></pre><p>Generally, event handlers are side-effecting operations which provide some
sort of inspection into the loop's progress. It's important to note that
if you define multiple handlers to be triggered on the same event, they
will execute in order from when they were attached to the training
loop:</p><pre><code class="makeup elixir" translate="no"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">handle_event</span><span class="p" data-group-id="9825017796-1">(</span><span class="ss">:epoch_started</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">normalize_step_state</span><span class="o">/</span><span class="mi">1</span><span class="p" data-group-id="9825017796-1">)</span><span class="w"> </span><span class="c1"># executes first</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">handle_event</span><span class="p" data-group-id="9825017796-2">(</span><span class="ss">:epoch_started</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">log_step_state</span><span class="o">/</span><span class="mi">1</span><span class="p" data-group-id="9825017796-2">)</span><span class="w"> </span><span class="c1"># executes second</span></code></pre><p>Thus, if you have separate handlers which alter or depend on loop state,
you need to ensure they are ordered correctly, or combined into a single
event handler for maximum control over execution.</p><p><code class="inline">event</code> must be an atom representing the event to trigger <code class="inline">handler</code> or a
list of atoms indicating <code class="inline">handler</code> should be triggered on multiple events.
<code class="inline">event</code> may be <code class="inline">:all</code> which indicates the handler should be triggered on
every event during loop processing.</p><p><code class="inline">handler</code> must be an arity-1 function which takes as input loop state and
returns <code class="inline">{status, state}</code>, where <code class="inline">status</code> is an atom with one of the following
values:</p><pre><code class="makeup elixir" translate="no"><span class="ss">:continue</span><span class="w">   </span><span class="c1"># Continue epoch, continue looping</span><span class="w">
</span><span class="ss">:halt_epoch</span><span class="w"> </span><span class="c1"># Halt the epoch, continue looping</span><span class="w">
</span><span class="ss">:halt_loop</span><span class="w">  </span><span class="c1"># Halt looping</span></code></pre><p><code class="inline">filter</code> is an atom representing a valid filter predicate, a keyword of
predicate-value pairs, or a function which takes loop state and returns
a <code class="inline">true</code>, indicating the handler should run, or <code class="inline">false</code>, indicating the
handler should not run. Valid predicates are:</p><pre><code class="makeup elixir" translate="no"><span class="ss">:always</span><span class="w"> </span><span class="c1"># Always trigger event</span><span class="w">
</span><span class="ss">:once</span><span class="w">   </span><span class="c1"># Trigger on first event firing</span></code></pre><p>Valid predicate-value pairs are:</p><pre><code class="makeup elixir" translate="no"><span class="ss">every</span><span class="p">:</span><span class="w"> </span><span class="nc">N</span><span class="w"> </span><span class="c1"># Trigger every `N` event</span><span class="w">
</span><span class="ss">only</span><span class="p">:</span><span class="w"> </span><span class="nc">N</span><span class="w"> </span><span class="c1"># Trigger on `N` event</span></code></pre><p><strong>Warning: If you modify the step state in an event handler, it will trigger
potentially excessive recompilation and result in significant additinal overhead
during loop execution.</strong></p>
  </section>
</section>
<section class="detail" id="kino_vega_lite_plot/4">

    <span id="kino_vega_lite_plot/3"></span>

  <div class="detail-header">
    <a href="#kino_vega_lite_plot/4" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">kino_vega_lite_plot(loop, plot, metric, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1433" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a handler function which updates a <a href="https://hexdocs.pm/kino_vega_lite/0.1.8/Kino.VegaLite.html"><code class="inline">Kino.VegaLite</code></a> plot.</p><p>By default, this will run after every iteration.</p><p>You must specify a plot to push to and a metric to track. The <code class="inline">:x</code> axis will be the iteration count, labeled <code class="inline">&quot;step&quot;</code>. The metric must match the name given to the <code class="inline">:y</code> axis in your <a href="https://hexdocs.pm/vega_lite/0.1.6/VegaLite.html"><code class="inline">VegaLite</code></a> plot:</p><pre><code class="makeup elixir" translate="no"><span class="n">plot</span><span class="w"> </span><span class="o">=</span><span class="w">
  </span><span class="nc">Vl</span><span class="o">.</span><span class="n">new</span><span class="p" data-group-id="6870341105-1">(</span><span class="p" data-group-id="6870341105-1">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Vl</span><span class="o">.</span><span class="n">mark</span><span class="p" data-group-id="6870341105-2">(</span><span class="ss">:line</span><span class="p" data-group-id="6870341105-2">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Vl</span><span class="o">.</span><span class="n">encode_field</span><span class="p" data-group-id="6870341105-3">(</span><span class="ss">:x</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;step&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">type</span><span class="p">:</span><span class="w"> </span><span class="ss">:quantitative</span><span class="p" data-group-id="6870341105-3">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Vl</span><span class="o">.</span><span class="n">encode_field</span><span class="p" data-group-id="6870341105-4">(</span><span class="ss">:y</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;loss&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">type</span><span class="p">:</span><span class="w"> </span><span class="ss">:quantitative</span><span class="p" data-group-id="6870341105-4">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Kino.VegaLite</span><span class="o">.</span><span class="n">new</span><span class="p" data-group-id="6870341105-5">(</span><span class="p" data-group-id="6870341105-5">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Kino</span><span class="o">.</span><span class="n">render</span><span class="p" data-group-id="6870341105-6">(</span><span class="p" data-group-id="6870341105-6">)</span><span class="w">

</span><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="6870341105-7">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">optim</span><span class="p" data-group-id="6870341105-7">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">kino_vega_lite_plot</span><span class="p" data-group-id="6870341105-8">(</span><span class="n">plot</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;loss&quot;</span><span class="p" data-group-id="6870341105-8">)</span></code></pre><h2 id="kino_vega_lite_plot/4-options" class="section-heading">
  <a href="#kino_vega_lite_plot/4-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><p><code class="inline">:event</code> - event to fire handler on. Defaults to <code class="inline">:iteration_completed</code>.</p></li><li><p><code class="inline">:filter</code> - event filter to attach to handler. Defaults to <code class="inline">:always</code>.</p></li></ul>
  </section>
</section>
<section class="detail" id="log/3">

    <span id="log/2"></span>

  <div class="detail-header">
    <a href="#log/3" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">log(loop, message_fn, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L981" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a handler function which logs the given message produced
by <code class="inline">message_fn</code> to the given IO device every <code class="inline">event</code> satisfying
<code class="inline">filter</code>.</p><p>In most cases, this is useful for inspecting the contents of
the loop state at intermediate stages. For example, the default
<code class="inline">trainer</code> loop factory attaches IO logging of epoch, batch, loss
and metrics.</p><p>It's also possible to log loop state to files by changing the
given IO device. By default, the IO device is <code class="inline">:stdio</code>.</p><p><code class="inline">message_fn</code> should take the loop state and return a binary
representing the message to be written to the IO device.</p>
  </section>
</section>
<section class="detail" id="loop/3">

    <span id="loop/1"></span>

    <span id="loop/2"></span>

  <div class="detail-header">
    <a href="#loop/3" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">loop(step_fn, init_fn \\ &amp;default_init/2, output_transform \\ &amp; &amp;1)</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L586" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Creates a loop from <code class="inline">step_fn</code>, an optional <code class="inline">init_fn</code>, and an
optional <code class="inline">output_transform</code>.</p><p><code class="inline">step_fn</code> is an arity-2 function which takes a batch and state
and returns an updated step state:</p><pre><code class="makeup elixir" translate="no"><span class="kd">defn</span><span class="w"> </span><span class="nf">batch_step</span><span class="p" data-group-id="2743626026-1">(</span><span class="n">batch</span><span class="p">,</span><span class="w"> </span><span class="n">step_state</span><span class="p" data-group-id="2743626026-1">)</span><span class="w"> </span><span class="k" data-group-id="2743626026-2">do</span><span class="w">
  </span><span class="n">step_state</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w">
</span><span class="k" data-group-id="2743626026-2">end</span></code></pre><p><code class="inline">init_fn</code> by default is an identity function which forwards its
initial arguments as the model state. You should define a custom
initialization function if you require a different behavior:</p><pre><code class="makeup elixir" translate="no"><span class="kd">defn</span><span class="w"> </span><span class="nf">init_step_state</span><span class="p" data-group-id="3296264309-1">(</span><span class="n">state</span><span class="p" data-group-id="3296264309-1">)</span><span class="w"> </span><span class="k" data-group-id="3296264309-2">do</span><span class="w">
  </span><span class="nc">Map</span><span class="o">.</span><span class="n">merge</span><span class="p" data-group-id="3296264309-3">(</span><span class="p" data-group-id="3296264309-4">%{</span><span class="ss">foo</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p" data-group-id="3296264309-4">}</span><span class="p">,</span><span class="w"> </span><span class="n">state</span><span class="p" data-group-id="3296264309-3">)</span><span class="w">
</span><span class="k" data-group-id="3296264309-2">end</span></code></pre><p>You may use <code class="inline">state</code> in conjunction with initialization functions in
<code class="inline">init_fn</code>. For example, <a href="#train_step/3"><code class="inline">train_step/3</code></a> uses initial state as initial
model parameters to allow initializing models from partial parameterizations.</p><p><code class="inline">step_batch/2</code> and <code class="inline">init_step_state/1</code> are typically called from
within <a href="https://hexdocs.pm/nx/0.5.3/Nx.Defn.html#jit/3"><code class="inline">Nx.Defn.jit/3</code></a>. While JIT-compilation will work with anonymous functions,
<code class="inline">def</code>, and <code class="inline">defn</code>, it is recommended that you use the stricter <code class="inline">defn</code> to define
both functions in order to avoid bugs or cryptic errors.</p><p><code class="inline">output_transform/1</code> applies a transformation on the final accumulated loop state.
This is useful for extracting specific fields from a loop and piping them into
additional functions.</p>
  </section>
</section>
<section class="detail" id="metric/5">

    <span id="metric/2"></span>

    <span id="metric/3"></span>

    <span id="metric/4"></span>

  <div class="detail-header">
    <a href="#metric/5" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">metric(loop, metric, name \\ nil, accumulate \\ :running_average, transform_or_fields \\ [:y_true, :y_pred])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L845" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a metric of the given name to the loop.</p><p>A metric is a function which tracks or measures some value with respect
to values in the step state. For example, when training classification
models, it's common to track the model's accuracy during training:</p><pre><code class="makeup elixir" translate="no"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="0796384912-1">(</span><span class="ss">:accuracy</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Accuracy&quot;</span><span class="p" data-group-id="0796384912-1">)</span></code></pre><p>By default, metrics assume a supervised learning task and extract the fields
<code class="inline">[:y_true, :y_pred]</code> from the step state. If you wish to work on a different
value, you can use an output transform. An output transform is a list of keys
to extract from the output state, or a function which returns a flattened list
of values to pass to the given metric function. Values received from output
transforms are passed to the given metric using:</p><pre><code class="makeup elixir" translate="no"><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output_transform</span><span class="o">.</span><span class="p" data-group-id="3937511094-1">(</span><span class="n">step_state</span><span class="p" data-group-id="3937511094-1">)</span><span class="w">
</span><span class="n">apply</span><span class="p" data-group-id="3937511094-2">(</span><span class="n">metric</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p" data-group-id="3937511094-2">)</span></code></pre><p>Thus, even if you want your metric to work on a container, your output transform
must return a list.</p><p><code class="inline">metric</code> must be an atom which matches the name of a metric in <a href="Axon.Metrics.html"><code class="inline">Axon.Metrics</code></a>, or
an arbitrary function which returns a tensor or container.</p><p><code class="inline">name</code> must be a string or atom used to store the computed metric in the loop
state. If names conflict, the last attached metric will take precedence:</p><pre><code class="makeup elixir" translate="no"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="0651003850-1">(</span><span class="ss">:mean_squared_error</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Error&quot;</span><span class="p" data-group-id="0651003850-1">)</span><span class="w"> </span><span class="c1"># Will be overwritten</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="0651003850-2">(</span><span class="ss">:mean_absolute_error</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Error&quot;</span><span class="p" data-group-id="0651003850-2">)</span><span class="w"> </span><span class="c1"># Will be used</span></code></pre><p>By default, metrics keep a running average of the metric calculation. You can
override this behavior by changing <code class="inline">accumulate</code>:</p><pre><code class="makeup elixir" translate="no"><span class="n">loop</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="9162500220-1">(</span><span class="ss">:true_negatives</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;tn&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">:running_sum</span><span class="p" data-group-id="9162500220-1">)</span></code></pre><p>Accumulation function can be one of the accumulation combinators in Axon.Metrics
or an arity-3 function of the form: <code class="inline">accumulate(acc, obs, i) :: new_acc</code>.</p>
  </section>
</section>
<section class="detail" id="monitor/5">

    <span id="monitor/4"></span>

  <div class="detail-header">
    <a href="#monitor/5" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">monitor(loop, metric, fun, name, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1112" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a handler function which monitors the given metric
and fires some action when the given metric meets some
criteria.</p><p>This function is a generalization of handlers such as
<a href="#reduce_lr_on_plateau/3"><code class="inline">Axon.Loop.reduce_lr_on_plateau/3</code></a> and <a href="#early_stop/3"><code class="inline">Axon.Loop.early_stop/3</code></a>.</p><p>You must specify a metric to monitor that is present in
the state metrics. This handler will then monitor the value
of the metric at the specified intervals and fire the specified
function if the criteria is met.</p><p>You must also specify a name for the monitor attached to the
given metric. This will be used to store metadata associated
with the monitor.</p><p>The common case of monitor is to track improvement of metrics
and take action if metrics haven't improved after a certain number
of events. However, you can also set a monitor up to trigger if
a metric hits some criteria (such as a threshold) by passing a
custom monitoring mode.</p><h2 id="monitor/5-options" class="section-heading">
  <a href="#monitor/5-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><p><code class="inline">:event</code> - event to fire handler on. Defaults to <code class="inline">:epoch_completed</code>.</p></li><li><p><code class="inline">:filter</code> - event filter to attach to handler. Defaults to <code class="inline">:always</code>.</p></li><li><p><code class="inline">:patience</code> - number of given events to wait for improvement. Defaults
to <code class="inline">3</code>.</p></li><li><p><code class="inline">:mode</code> - whether given metric is being minimized or maximized. One of
<code class="inline">:min</code>, <code class="inline">:max</code> or an arity-1 function which returns <code class="inline">true</code> or <code class="inline">false</code>.
Defaults to <code class="inline">:min</code>.</p></li></ul>
  </section>
</section>
<section class="detail" id="reduce_lr_on_plateau/3">

    <span id="reduce_lr_on_plateau/2"></span>

  <div class="detail-header">
    <a href="#reduce_lr_on_plateau/3" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">reduce_lr_on_plateau(loop, monitor, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1372" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a handler function which reduces the learning rate by
the given factor if the given metric does not improve between
events.</p><p>By default, this will run after each epoch and track the
improvement of a given metric.</p><p>You must specify a metric to monitor and the metric must
be present in the loop state. Typically, this will be
a validation metric:</p><pre><code class="makeup elixir" translate="no"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="8892495871-1">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">optim</span><span class="p" data-group-id="8892495871-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="8892495871-2">(</span><span class="ss">:accuracy</span><span class="p" data-group-id="8892495871-2">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">validate</span><span class="p" data-group-id="8892495871-3">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">val_data</span><span class="p" data-group-id="8892495871-3">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">reduce_lr_on_plateau</span><span class="p" data-group-id="8892495871-4">(</span><span class="s">&quot;accuracy&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">mode</span><span class="p">:</span><span class="w"> </span><span class="ss">:max</span><span class="p" data-group-id="8892495871-4">)</span></code></pre><h2 id="reduce_lr_on_plateau/3-options" class="section-heading">
  <a href="#reduce_lr_on_plateau/3-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><p><code class="inline">:event</code> - event to fire handler on. Defaults to <code class="inline">:epoch_completed</code>.</p></li><li><p><code class="inline">:filter</code> - event filter to attach to handler. Defaults to <code class="inline">:always</code>.</p></li><li><p><code class="inline">:patience</code> - number of given events to wait for improvement. Defaults
to <code class="inline">3</code>.</p></li><li><p><code class="inline">:mode</code> - whether given metric is being minimized or maximized. Defaults
to <code class="inline">:min</code>.</p></li><li><p><code class="inline">:factor</code> - factor to decrease learning rate by. Defaults to <code class="inline">0.1</code>.</p></li></ul>
  </section>
</section>
<section class="detail" id="run/4">

    <span id="run/2"></span>

    <span id="run/3"></span>

  <div class="detail-header">
    <a href="#run/4" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">run(loop, data, init_state \\ %{}, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1588" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Runs the given loop on data with the given options.</p><p><code class="inline">loop</code> must be a valid Axon.Loop struct built from one of the
loop factories provided in this module.</p><p><code class="inline">data</code> must be an Enumerable or Stream which yields batches of
data on each iteration.</p><h2 id="run/4-options" class="section-heading">
  <a href="#run/4-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><p><code class="inline">:epochs</code> - max epochs to run loop for. Must be non-negative integer.
Defaults to <code class="inline">1</code>.</p></li><li><p><code class="inline">:iterations</code> - max iterations to run each epoch. Must be non-negative
integer. Defaults to <code class="inline">-1</code> or no max iterations.</p></li><li><p><code class="inline">:jit_compile?</code> - whether or not to JIT compile initialization and step
functions. JIT compilation must be used for gradient computations. Defaults
to true.</p></li><li><p><code class="inline">:strict?</code> - whether or not to compile step functions strictly. If this flag
is set, the loop will raise on any cache miss during the training loop. Defaults
to true.</p></li><li><p><code class="inline">:debug</code> - run loop in debug mode to trace loop progress. Defaults to
false.</p></li></ul><p>  Additional options are forwarded to <code class="inline">Nx.Defn.jit</code> as JIT-options. If no JIT
  options are set, the default options set with <code class="inline">Nx.Defn.default_options</code> are
  used.</p>
  </section>
</section>
<section class="detail" id="serialize_state/2">

    <span id="serialize_state/1"></span>

  <div class="detail-header">
    <a href="#serialize_state/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">serialize_state(state, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1524" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Serializes loop state to a binary for saving and loading
loop from previous states.</p><p>You can consider the serialized state to be a checkpoint of
all state at a given iteration and epoch.</p><p>By default, the step state is serialized using <a href="https://hexdocs.pm/nx/0.5.3/Nx.html#serialize/2"><code class="inline">Nx.serialize/2</code></a>;
however, this behavior can be changed if step state is an application
specific container. For example, if you introduce your own data
structure into step_state, <a href="https://hexdocs.pm/nx/0.5.3/Nx.html#serialize/2"><code class="inline">Nx.serialize/2</code></a> will not be sufficient
for serialization - you must pass custom serialization as an option
with <code class="inline">:serialize_step_state</code>.</p><p>Additional <code class="inline">opts</code> controls serialization options such as compression.
It is forwarded to <a href="https://www.erlang.org/doc/man/erlang.html#term_to_binary-2"><code class="inline">:erlang.term_to_binary/2</code></a>.</p>
  </section>
</section>
<section class="detail" id="train_step/4">

    <span id="train_step/3"></span>

  <div class="detail-header">
    <a href="#train_step/4" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">train_step(model, loss, optimizer, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L332" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Creates a supervised train step from a model, loss function, and
optimizer.</p><p>This function is intended for more fine-grained control over the loop
creation process. It returns a tuple of <code class="inline">{init_fn, step_fn}</code> where <code class="inline">init_fn</code>
is an initialization function which returns an initial step state and
<code class="inline">step_fn</code> is a supervised train step constructed from <code class="inline">model</code>, <code class="inline">loss</code>,
and <code class="inline">optimizer</code>.</p><p><code class="inline">model</code> must be an Axon struct, a valid defn container
of Axon structs, or a <code class="inline">{init_fn, apply_fn}</code>-tuple where <code class="inline">init_fn</code> is
an arity-2 function which initializes the model state and <code class="inline">apply_fn</code> is
an arity-2 function which applies the forward pass of the model. The forward
pass of the model must return a map with keys <code class="inline">:prediction</code> and <code class="inline">:state</code>
representing the model's prediction and updated state for layers which
aggregate state during training.</p><p><code class="inline">loss</code> must be an atom which matches a function in <a href="Axon.Losses.html"><code class="inline">Axon.Losses</code></a>, a list
of <code class="inline">{loss, weight}</code> tuples representing a basic weighted loss function
for multi-output models, or an arity-2 function representing a custom loss
function.</p><p><code class="inline">optimizer</code> must be an atom matching the name of a valid optimizer in <a href="https://hexdocs.pm/polaris/0.1.0/Polaris.Optimizers.html"><code class="inline">Polaris.Optimizers</code></a>,
or a <code class="inline">{init_fn, update_fn}</code> tuple where <code class="inline">init_fn</code> is an arity-1 function which
initializes the optimizer state from the model parameters and <code class="inline">update_fn</code> is an
arity-3 function that receives <code class="inline">(gradient, optimizer_state, model_parameters)</code> and
scales gradient updates with respect to input parameters, optimizer state, and gradients.
The <code class="inline">update_fn</code> returns <code class="inline">{scaled_updates, optimizer_state}</code>, which can then be applied to
the model through <code class="inline">model_parameters = Axon.Update.apply_updates(model_parameters, scaled_updates)</code>.
See <a href="https://hexdocs.pm/polaris/0.1.0/Polaris.Updates.html"><code class="inline">Polaris.Updates</code></a> for more information on building optimizers.</p><h2 id="train_step/4-options" class="section-heading">
  <a href="#train_step/4-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><p><code class="inline">:seed</code> - seed to use when constructing models. Seed controls random initialization
of model parameters. Defaults to no seed which constructs a random seed for you at
model build time.</p></li><li><p><code class="inline">:loss_scale</code> - type of loss-scaling to use, if any. Loss-scaling is necessary when
doing mixed precision training for numerical stability. Defaults to <code class="inline">:identity</code> or
no loss-scaling.</p></li><li><p><code class="inline">:gradient_accumulation_steps</code> - number of gradient accumulation steps to take during
training. Gradient accumulation decreases the number of updates by accumulating gradients
between steps, increasing the effective batch size on smaller devices. Defaults to 1.</p></li></ul>
  </section>
</section>
<section class="detail" id="trainer/4">

    <span id="trainer/3"></span>

  <div class="detail-header">
    <a href="#trainer/4" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">trainer(model, loss, optimizer, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L694" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Creates a supervised training loop from a model, loss function,
and optimizer.</p><p>This function is useful for training models on most standard supervised
learning tasks. It assumes data consists of tuples of input-target pairs,
e.g. <code class="inline">[{x0, y0}, {x1, y1}, ..., {xN, yN}]</code> where <code class="inline">x0</code> and <code class="inline">y0</code> are batched
tensors or containers of batched tensors.</p><p>It defines an initialization function which first initializes model state
using the given model and then initializes optimizer state using the initial
model state. The step function uses a differentiable objective function
defined with respect to the model parameters, input data, and target data
using the given loss function. It then updates model parameters using the
given optimizer in order to minimize loss with respect to the model parameters.</p><p><code class="inline">model</code> must be an Axon struct, a valid defn container
of Axon structs, or a <code class="inline">{init_fn, apply_fn}</code>-tuple where <code class="inline">init_fn</code> is
an arity-2 function which initializes the model state and <code class="inline">apply_fn</code> is
an arity-2 function which applies the forward pass of the model.</p><p><code class="inline">loss</code> must be an atom which matches a function in <a href="Axon.Losses.html"><code class="inline">Axon.Losses</code></a>, a list
of <code class="inline">{loss, weight}</code> tuples representing a basic weighted loss function
for multi-output models, or an arity-2 function representing a custom loss
function.</p><p><code class="inline">optimizer</code> must be an atom matching the name of a valid optimizer in <a href="https://hexdocs.pm/polaris/0.1.0/Polaris.Optimizers.html"><code class="inline">Polaris.Optimizers</code></a>,
or a <code class="inline">{init_fn, update_fn}</code> tuple where <code class="inline">init_fn</code> is an arity-1 function which
initializes the optimizer state from attached parameters and <code class="inline">update_fn</code> is an
arity-3 function which scales gradient updates with respect to input parameters,
optimizer state, and gradients. See <a href="https://hexdocs.pm/polaris/0.1.0/Polaris.Updates.html"><code class="inline">Polaris.Updates</code></a> for more information on building
optimizers.</p><p>This function creates a step function which outputs a map consisting of the following
fields for <code class="inline">step_state</code>:</p><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="9039575166-1">%{</span><span class="w">
  </span><span class="ss">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">tensor</span><span class="p" data-group-id="9039575166-2">(</span><span class="p" data-group-id="9039575166-2">)</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="9039575166-3">(</span><span class="n">tensor</span><span class="p" data-group-id="9039575166-4">(</span><span class="p" data-group-id="9039575166-4">)</span><span class="p" data-group-id="9039575166-3">)</span><span class="p">,</span><span class="w"> </span><span class="c1"># Model predictions for use in metrics</span><span class="w">
  </span><span class="ss">y_true</span><span class="p">:</span><span class="w"> </span><span class="n">tensor</span><span class="p" data-group-id="9039575166-5">(</span><span class="p" data-group-id="9039575166-5">)</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="9039575166-6">(</span><span class="n">tensor</span><span class="p" data-group-id="9039575166-7">(</span><span class="p" data-group-id="9039575166-7">)</span><span class="p" data-group-id="9039575166-6">)</span><span class="p">,</span><span class="w"> </span><span class="c1"># True labels for use in metrics</span><span class="w">
  </span><span class="ss">loss</span><span class="p">:</span><span class="w"> </span><span class="n">tensor</span><span class="p" data-group-id="9039575166-8">(</span><span class="p" data-group-id="9039575166-8">)</span><span class="p">,</span><span class="w"> </span><span class="c1"># Running average of loss over epoch</span><span class="w">
  </span><span class="ss">model_state</span><span class="p">:</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="9039575166-9">(</span><span class="n">tensor</span><span class="p" data-group-id="9039575166-10">(</span><span class="p" data-group-id="9039575166-10">)</span><span class="p" data-group-id="9039575166-9">)</span><span class="p">,</span><span class="w"> </span><span class="c1"># Model parameters and state</span><span class="w">
  </span><span class="ss">optimizer_state</span><span class="p">:</span><span class="w"> </span><span class="n">container</span><span class="p" data-group-id="9039575166-11">(</span><span class="n">tensor</span><span class="p" data-group-id="9039575166-12">(</span><span class="p" data-group-id="9039575166-12">)</span><span class="p" data-group-id="9039575166-11">)</span><span class="w"> </span><span class="c1"># Optimizer state associated with each parameter</span><span class="w">
</span><span class="p" data-group-id="9039575166-1">}</span></code></pre><h2 id="trainer/4-examples" class="section-heading">
  <a href="#trainer/4-examples" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">examples</p>
  </a>
  Examples
</h2>
<h3 id="trainer/4-basic-usage" class="section-heading">
  <a href="#trainer/4-basic-usage" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">basic-usage</p>
  </a>
  Basic usage
</h3>
<pre><code class="makeup elixir" translate="no"><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Stream</span><span class="o">.</span><span class="n">zip</span><span class="p" data-group-id="9380434001-1">(</span><span class="n">input</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="p" data-group-id="9380434001-1">)</span><span class="w">

</span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">input</span><span class="p" data-group-id="9380434001-2">(</span><span class="s">&quot;input&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">shape</span><span class="p">:</span><span class="w"> </span><span class="p" data-group-id="9380434001-3">{</span><span class="no">nil</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p" data-group-id="9380434001-3">}</span><span class="p" data-group-id="9380434001-2">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">dense</span><span class="p" data-group-id="9380434001-4">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="ss">activation</span><span class="p">:</span><span class="w"> </span><span class="ss">:sigmoid</span><span class="p" data-group-id="9380434001-4">)</span><span class="w">

</span><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="9380434001-5">(</span><span class="ss">:binary_cross_entropy</span><span class="p">,</span><span class="w"> </span><span class="ss">:adam</span><span class="p" data-group-id="9380434001-5">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="9380434001-6">(</span><span class="n">data</span><span class="p" data-group-id="9380434001-6">)</span></code></pre><h3 id="trainer/4-customizing-optimizer" class="section-heading">
  <a href="#trainer/4-customizing-optimizer" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">customizing-optimizer</p>
  </a>
  Customizing Optimizer
</h3>
<pre><code class="makeup elixir" translate="no"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="0040774355-1">(</span><span class="ss">:binary_cross_entropy</span><span class="p">,</span><span class="w"> </span><span class="nc">Polaris.Optimizers</span><span class="o">.</span><span class="n">adam</span><span class="p" data-group-id="0040774355-2">(</span><span class="ss">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="mf">0.05</span><span class="p" data-group-id="0040774355-2">)</span><span class="p" data-group-id="0040774355-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="0040774355-3">(</span><span class="n">data</span><span class="p" data-group-id="0040774355-3">)</span></code></pre><h3 id="trainer/4-custom-loss" class="section-heading">
  <a href="#trainer/4-custom-loss" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">custom-loss</p>
  </a>
  Custom loss
</h3>
<pre><code class="makeup elixir" translate="no"><span class="n">loss_fn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k" data-group-id="1210915240-1">fn</span><span class="w"> </span><span class="n">y_true</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">cos</span><span class="p" data-group-id="1210915240-2">(</span><span class="n">y_true</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p" data-group-id="1210915240-2">)</span><span class="w"> </span><span class="k" data-group-id="1210915240-1">end</span><span class="w">

</span><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="1210915240-3">(</span><span class="n">loss_fn</span><span class="p">,</span><span class="w"> </span><span class="nc">Polaris.Optimizers</span><span class="o">.</span><span class="n">rmsprop</span><span class="p" data-group-id="1210915240-4">(</span><span class="ss">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="mf">0.01</span><span class="p" data-group-id="1210915240-4">)</span><span class="p" data-group-id="1210915240-3">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="1210915240-5">(</span><span class="n">data</span><span class="p" data-group-id="1210915240-5">)</span></code></pre><h3 id="trainer/4-multiple-objectives-with-multi-output-model" class="section-heading">
  <a href="#trainer/4-multiple-objectives-with-multi-output-model" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">multiple-objectives-with-multi-output-model</p>
  </a>
  Multiple objectives with multi-output model
</h3>
<pre><code class="makeup elixir" translate="no"><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="3790297787-1">{</span><span class="nc">Axon</span><span class="o">.</span><span class="n">input</span><span class="p" data-group-id="3790297787-2">(</span><span class="s">&quot;input_0&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">shape</span><span class="p">:</span><span class="w"> </span><span class="p" data-group-id="3790297787-3">{</span><span class="no">nil</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p" data-group-id="3790297787-3">}</span><span class="p" data-group-id="3790297787-2">)</span><span class="p">,</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">input</span><span class="p" data-group-id="3790297787-4">(</span><span class="s">&quot;input_1&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">shape</span><span class="p">:</span><span class="w"> </span><span class="p" data-group-id="3790297787-5">{</span><span class="no">nil</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p" data-group-id="3790297787-5">}</span><span class="p" data-group-id="3790297787-4">)</span><span class="p" data-group-id="3790297787-1">}</span><span class="w">
</span><span class="n">loss_weights</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="3790297787-6">[</span><span class="ss">mean_squared_error</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="ss">mean_absolute_error</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="p" data-group-id="3790297787-6">]</span><span class="w">

</span><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="3790297787-7">(</span><span class="n">loss_weights</span><span class="p">,</span><span class="w"> </span><span class="ss">:sgd</span><span class="p" data-group-id="3790297787-7">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="3790297787-8">(</span><span class="n">data</span><span class="p" data-group-id="3790297787-8">)</span></code></pre><h2 id="trainer/4-options" class="section-heading">
  <a href="#trainer/4-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><p><code class="inline">:log</code> - training loss and metric log interval. Set to 0 to silence
training logs. Defaults to 50</p></li><li><p><code class="inline">:seed</code> - seed to use when constructing models. Seed controls random initialization
of model parameters. Defaults to no seed which constructs a random seed for you at
model build time.</p></li><li><p><code class="inline">:loss_scale</code> - type of loss-scaling to use, if any. Loss-scaling is necessary when
doing mixed precision training for numerical stability. Defaults to <code class="inline">:identity</code> or
no loss-scaling.</p></li><li><p><code class="inline">:gradient_accumulation_steps</code> - number of gradient accumulation steps to take during
training. Gradient accumulation decreases the number of updates by accumulating gradients
between steps, increasing the effective batch size on smaller devices. Defaults to 1.</p></li></ul>
  </section>
</section>
<section class="detail" id="validate/4">

    <span id="validate/3"></span>

  <div class="detail-header">
    <a href="#validate/4" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">validate(loop, model, validation_data, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.5.1/lib/axon/loop.ex#L1047" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adds a handler function which tests the performance of <code class="inline">model</code>
against the given validation set.</p><p>This handler assumes the loop state matches the state initialized
in a supervised training loop. Typically, you'd call this immediately
after creating a supervised training loop:</p><pre><code class="makeup elixir" translate="no"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="6941939582-1">(</span><span class="ss">:mean_squared_error</span><span class="p">,</span><span class="w"> </span><span class="ss">:sgd</span><span class="p" data-group-id="6941939582-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">validate</span><span class="p" data-group-id="6941939582-2">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">validation_data</span><span class="p" data-group-id="6941939582-2">)</span></code></pre><p>Please note that you must pass the same (or an equivalent) model
into this method so it can be used during the validation loop. The
metrics which are computed are those which are present BEFORE the
validation handler was added to the loop. For the following loop:</p><pre><code class="makeup elixir" translate="no"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="7225695141-1">(</span><span class="ss">:mean_squared_error</span><span class="p">,</span><span class="w"> </span><span class="ss">:sgd</span><span class="p" data-group-id="7225695141-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="7225695141-2">(</span><span class="ss">:mean_absolute_error</span><span class="p" data-group-id="7225695141-2">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">validate</span><span class="p" data-group-id="7225695141-3">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">validation_data</span><span class="p" data-group-id="7225695141-3">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="7225695141-4">(</span><span class="ss">:binary_cross_entropy</span><span class="p" data-group-id="7225695141-4">)</span></code></pre><p>only <code class="inline">:mean_absolute_error</code> will be computed at validation time.</p><p>The returned loop state is altered to contain validation
metrics for use in later handlers such as early stopping and model
checkpoints. Since the order of execution of event handlers is in
the same order they are declared in the training loop, you MUST call
this method before any other handler which expects or may use
validation metrics.</p><p>By default the validation loop runs after every epoch; however, you
can customize it by overriding the default event and event filters:</p><pre><code class="makeup elixir" translate="no"><span class="n">model</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="2472362728-1">(</span><span class="ss">:mean_squared_error</span><span class="p">,</span><span class="w"> </span><span class="ss">:sgd</span><span class="p" data-group-id="2472362728-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="2472362728-2">(</span><span class="ss">:mean_absolute_error</span><span class="p" data-group-id="2472362728-2">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">validate</span><span class="p" data-group-id="2472362728-3">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">validation_data</span><span class="p">,</span><span class="w"> </span><span class="ss">event</span><span class="p">:</span><span class="w"> </span><span class="ss">:iteration_completed</span><span class="p">,</span><span class="w"> </span><span class="ss">filter</span><span class="p">:</span><span class="w"> </span><span class="p" data-group-id="2472362728-4">[</span><span class="ss">every</span><span class="p">:</span><span class="w"> </span><span class="mi">10_000</span><span class="p" data-group-id="2472362728-4">]</span><span class="p" data-group-id="2472362728-3">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">metric</span><span class="p" data-group-id="2472362728-5">(</span><span class="ss">:binary_cross_entropy</span><span class="p" data-group-id="2472362728-5">)</span></code></pre>
  </section>
</section>

    </div>
  </section>

      <footer class="footer">
        <p>

            <span class="line">
              <a href="https://hex.pm/packages/axon/0.5.1" class="footer-hex-package">Hex Package</a>

              <a href="https://preview.hex.pm/preview/axon/0.5.1">Hex Preview</a>

                (<a href="https://preview.hex.pm/preview/axon/0.5.1/show/lib/axon/loop.ex">current file</a>)

            </span>

          <span class="line">
            <button class="a-main footer-button display-quick-switch" title="Search HexDocs packages">
              Search HexDocs
            </button>

              <a href="Axon.epub" title="ePub version">
                Download ePub version
              </a>

          </span>
        </p>

        <p class="built-using">
          Built using
          <a href="https://github.com/elixir-lang/ex_doc" title="ExDoc" target="_blank" rel="help noopener" translate="no">ExDoc</a> (v0.29.3) for the

            <a href="https://elixir-lang.org" title="Elixir" target="_blank" translate="no">Elixir programming language</a>

        </p>
      </footer>
    </div>
  </div>
</section>
</div>

<!-- Render math with KaTeX -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css" integrity="sha384-t5CR+zwDAROtph0PXGte6ia8heboACF9R5l/DiY+WZ3P2lxNgvJkQk5n7GPvLMYw" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js" integrity="sha384-FaFLTlohFghEIZkw6VGwmf9ISTubWAVYW8tG8+w2LAIftJEULZABrF9PPFv+tVkH" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js" integrity="sha384-bHBqxz8fokvgoJ/sc17HODNxa42TlaEhB+w8ZJXTc2nZf1VgEaFZeZvT4Mznfz0v" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
      ]
    });
  });
</script>

<!-- Render diagrams with Mermaid -->
<script src="https://cdn.jsdelivr.net/npm/mermaid@8.13.3/dist/mermaid.min.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    mermaid.initialize({ startOnLoad: false });
    let id = 0;
    for (const codeEl of document.querySelectorAll("pre code.mermaid")) {
      const preEl = codeEl.parentElement;
      const graphDefinition = codeEl.textContent;
      const graphEl = document.createElement("div");
      const graphId = "mermaid-graph-" + id++;
      mermaid.render(graphId, graphDefinition, function (svgSource, bindListeners) {
        graphEl.innerHTML = svgSource;
        bindListeners && bindListeners(graphEl);
        preEl.insertAdjacentElement("afterend", graphEl);
        preEl.remove();
      });
    }
  });
</script>

  </body>
</html>
