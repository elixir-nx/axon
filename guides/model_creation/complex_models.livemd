<!-- livebook:{"persist_outputs":true} -->

# Complex models

```elixir
Mix.install([
  {:axon, github: "elixir-nx/axon"},
  {:nx, "~> 0.3.0", github: "elixir-nx/nx", sparse: "nx", override: true},
  {:kino, "~> 0.7.0"}
])
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Creating more complex models

Not all models you'd want to create fit cleanly in the *sequential* paradigm. Some models require a more flexible API. Fortunately, because Axon models are just Elixir data structures, you can manipulate them and decompose architectures as you would any other Elixir program:

```elixir
input = Axon.input("data")

x1 = input |> Axon.dense(32)
x2 = input |> Axon.dense(64) |> Axon.relu() |> Axon.dense(32)

out = Axon.add(x1, x2)
```

<!-- livebook:{"output":true} -->

```
#Axon<
  inputs: %{"data" => nil}
  outputs: "add_0"
  nodes: 7
>
```

In the snippet above, your model branches `input` into `x1` and `x2`. Each branch performs a different set of transformations; however, at the end the branches are merged with an `Axon.add/3`. You might sometimes see layers like `Axon.add/3` called *combinators*. Really they're just layers that operate on multiple Axon models at once - typically to merge some branches together.

`out` represents your final Axon model.

If you visualize this model, you can see the full effect of the branching in this model:

```elixir
template = Nx.template({2, 8}, :f32)
Axon.Display.as_graph(out, template)
```

<!-- livebook:{"output":true} -->

```mermaid
graph TD;
3[/"data (:input) {2, 8}"/];
6["dense_0 (:dense) {2, 32}"];
9["dense_1 (:dense) {2, 64}"];
10["relu_0 (:relu) {2, 64}"];
13["dense_2 (:dense) {2, 32}"];
14["container_0 (:container) {{2, 32}, {2, 32}}"];
15["add_0 (:add) {2, 32}"];
14 --> 15;
13 --> 14;
6 --> 14;
10 --> 13;
9 --> 10;
3 --> 9;
3 --> 6;
```

And you can use `Axon.build/2` on `out` as you would any other Axon model:

```elixir
{init_fn, predict_fn} = Axon.build(out)
```

<!-- livebook:{"output":true} -->

```
{#Function<137.55749718/2 in Nx.Defn.wrap_arity/2>,
 #Function<137.55749718/2 in Nx.Defn.wrap_arity/2>}
```

```elixir
params = init_fn.(template, %{})
predict_fn.(params, Nx.iota({2, 8}, type: :f32))
```

<!-- livebook:{"output":true} -->

```
#Nx.Tensor<
  f32[2][32]
  [
    [1.0300962924957275, -0.7801889181137085, 1.9320738315582275, 2.449699878692627, 1.7780630588531494, 2.265313148498535, 1.8984736204147339, 2.9197654724121094, 1.292323112487793, 2.5680737495422363, -4.249234676361084, -0.731231689453125, 2.6717398166656494, 0.5598552227020264, -2.119790554046631, 1.0053789615631104, -0.006215333938598633, -0.8466284275054932, 1.3398749828338623, -5.065088272094727, -4.571428298950195, -4.864935874938965, 2.382566452026367, 3.6753427982330322, -3.984919786453247, 0.1264406442642212, 4.17943000793457, 2.040212392807007, 3.9746994972229004, 2.3652305603027344, -0.8487565517425537, 0.6926432847976685],
    [3.1355128288269043, -4.073042869567871, -2.553102493286133, 7.694198131561279, -0.31821298599243164, 8.51380729675293, 1.2917925119400024, 10.68221664428711, 4.475883483886719, 4.447973251342773, -13.187350273132324, 3.1627817153930664, 4.310325622558594, -1.133324384689331, -3.3722496032714844, 8.514323234558105, -4.439181804656982, -0.2023944854736328, ...]
  ]
>
```

As your architectures grow in complexity, you might find yourself reaching for better abstractions to organize your model creation code. For example, PyTorch models are often organized into `nn.Module`. The equivalent of an `nn.Module` in Axon is a regular Elixir function. If you're translating models from PyTorch to Axon, it's natural to create one Elixir function per `nn.Module`.

You should write your models as you would write any other Elixir code - you don't need to worry about any framework specific constructs:

```elixir
defmodule MyModel do
  def model() do
    Axon.input("data")
    |> conv_block()
    |> Axon.flatten()
    |> dense_block()
    |> dense_block()
    |> Axon.dense(1)
  end

  defp conv_block(input) do
    residual = input

    x = input |> Axon.conv(3, padding: :same) |> Axon.mish()

    x
    |> Axon.add(residual)
    |> Axon.max_pool(kernel_size: {2, 2})
  end

  defp dense_block(input) do
    input |> Axon.dense(32) |> Axon.relu()
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, MyModel, <<70, 79, 82, 49, 0, 0, 8, ...>>, {:dense_block, 1}}
```

```elixir
model = MyModel.model()
```

<!-- livebook:{"output":true} -->

```
#Axon<
  inputs: %{"data" => nil}
  outputs: "dense_2"
  nodes: 12
>
```

```elixir
template = Nx.template({1, 3, 28, 28}, :f32)
Axon.Display.as_graph(model, template)
```

<!-- livebook:{"output":true} -->

```mermaid
graph TD;
16[/"data (:input) {1, 3, 28, 28}"/];
19["conv_0 (:conv) {1, 3, 28, 28}"];
20["mish_0 (:mish) {1, 3, 28, 28}"];
21["container_0 (:container) {{1, 3, 28, 28}, {1, 3, 28, 28}}"];
22["add_0 (:add) {1, 3, 28, 28}"];
23["max_pool_0 (:max_pool) {1, 3, 14, 14}"];
24["flatten_0 (:flatten) {1, 588}"];
27["dense_0 (:dense) {1, 32}"];
28["relu_0 (:relu) {1, 32}"];
31["dense_1 (:dense) {1, 32}"];
32["relu_1 (:relu) {1, 32}"];
35["dense_2 (:dense) {1, 1}"];
32 --> 35;
31 --> 32;
28 --> 31;
27 --> 28;
24 --> 27;
23 --> 24;
22 --> 23;
21 --> 22;
16 --> 21;
20 --> 21;
19 --> 20;
16 --> 19;
```
