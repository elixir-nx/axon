<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="ExDoc v0.31.1">
    <meta name="project" content="Axon v0.6.1">


    <title>Converting ONNX models to Axon — Axon v0.6.1</title>
    <link rel="stylesheet" href="dist/html-elixir-FM2CSD74.css" />


    <script src="dist/handlebars.runtime-NWIB6V2M.js"></script>
    <script src="dist/handlebars.templates-43PMFBC7.js"></script>
    <script src="dist/sidebar_items-B66D7C0E.js"></script>

      <script src="docs_config.js"></script>

    <script async src="dist/html-L4O5OK2K.js"></script>


  </head>
  <body data-type="extras" class="page-livemd">
    <script>

      try {
        var settings = JSON.parse(localStorage.getItem('ex_doc:settings') || '{}');

        if (settings.theme === 'dark' ||
           ((settings.theme === 'system' || settings.theme == null) &&
             window.matchMedia('(prefers-color-scheme: dark)').matches)
           ) {
          document.body.classList.add('dark')
        }
      } catch (error) { }
    </script>

<div class="main">

<button id="sidebar-menu" class="sidebar-button sidebar-toggle" aria-label="toggle sidebar" aria-controls="sidebar">
  <i class="ri-menu-line ri-lg" title="Collapse/expand sidebar"></i>
</button>

<div class="background-layer"></div>

<nav id="sidebar" class="sidebar">

  <div class="sidebar-header">
    <div class="sidebar-projectInfo">

        <a href="Axon.html" class="sidebar-projectImage">
          <img src="assets/logo.png" alt="Axon" />
        </a>

      <div>
        <a href="Axon.html" class="sidebar-projectName" translate="no">
Axon
        </a>
        <div class="sidebar-projectVersion" translate="no">
          v0.6.1
        </div>
      </div>
    </div>
    <ul id="sidebar-listNav" class="sidebar-listNav" role="tablist">
      <li>
        <button id="extras-list-tab-button" role="tab" data-type="extras" aria-controls="extras-tab-panel" aria-selected="true" tabindex="0">
Pages
        </button>
      </li>

        <li>
          <button id="modules-list-tab-button" role="tab" data-type="modules" aria-controls="modules-tab-panel" aria-selected="false" tabindex="-1">
            Modules
          </button>
        </li>


    </ul>
  </div>

  <div id="extras-tab-panel" class="sidebar-tabpanel" role="tabpanel" aria-labelledby="extras-list-tab-button">
    <ul id="extras-full-list" class="full-list"></ul>
  </div>

    <div id="modules-tab-panel" class="sidebar-tabpanel" role="tabpanel" aria-labelledby="modules-list-tab-button" hidden>
      <ul id="modules-full-list" class="full-list"></ul>
    </div>


</nav>

<main class="content">
  <output role="status" id="toast"></output>
  <div class="content-outer">
    <div id="content" class="content-inner">
      <div class="top-search">
        <div class="search-settings">
          <form class="search-bar" action="search.html">
            <label class="search-label">
              <span class="sr-only">Search documentation of Axon</span>
              <input name="q" type="text" class="search-input" placeholder="Search Documentation (press /)" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" />
            </label>
            <button type="submit" class="search-button" aria-label="Submit Search">
              <i class="ri-search-2-line ri-lg" aria-hidden="true" title="Submit search"></i>
            </button>
            <button type="button" tabindex="-1" class="search-close-button" aria-hidden="true">
              <i class="ri-close-line ri-lg" title="Cancel search"></i>
            </button>
          </form>
          <div class="autocomplete">
          </div>
          <button class="icon-settings display-settings">
            <i class="ri-settings-3-line"></i>
            <span class="sr-only">Settings</span>
          </button>
        </div>

      </div>

<h1>

    <a href="https://github.com/elixir-nx/axon/blob/v0.6.1/guides/serialization/onnx_to_axon.livemd#L1" title="View Source" class="icon-action" rel="help">
      <i class="ri-code-s-slash-line" aria-hidden="true"></i>
      <span class="sr-only">View Source</span>
    </a>


  <span>Converting ONNX models to Axon</span>
</h1>

  <div class="livebook-badge-container">
    <a href="#" class="livebook-badge">
      <img src="https://livebook.dev/badge/v1/blue.svg" alt="Run in Livebook" width="150" />
    </a>
  </div>

<pre><code class="makeup elixir" translate="no"><span class="nc">Mix</span><span class="o">.</span><span class="n">install</span><span class="p" data-group-id="1634817522-1">(</span><span class="w">
  </span><span class="p" data-group-id="1634817522-2">[</span><span class="w">
    </span><span class="p" data-group-id="1634817522-3">{</span><span class="ss">:axon</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&gt;= 0.5.0&quot;</span><span class="p" data-group-id="1634817522-3">}</span><span class="p">,</span><span class="w">
    </span><span class="p" data-group-id="1634817522-4">{</span><span class="ss">:exla</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&gt;= 0.5.0&quot;</span><span class="p" data-group-id="1634817522-4">}</span><span class="p">,</span><span class="w">
    </span><span class="p" data-group-id="1634817522-5">{</span><span class="ss">:axon_onnx</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&gt;= 0.4.0&quot;</span><span class="p" data-group-id="1634817522-5">}</span><span class="p">,</span><span class="w">
    </span><span class="p" data-group-id="1634817522-6">{</span><span class="ss">:stb_image</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&gt;= 0.6.0&quot;</span><span class="p" data-group-id="1634817522-6">}</span><span class="p">,</span><span class="w">
    </span><span class="p" data-group-id="1634817522-7">{</span><span class="ss">:kino</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&gt;= 0.9.0&quot;</span><span class="p" data-group-id="1634817522-7">}</span><span class="p">,</span><span class="w">
    </span><span class="p" data-group-id="1634817522-8">{</span><span class="ss">:req</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&gt;= 0.3.8&quot;</span><span class="p" data-group-id="1634817522-8">}</span><span class="w">
  </span><span class="p" data-group-id="1634817522-2">]</span><span class="w">
  </span><span class="c1"># for Nvidia GPU change to &quot;cuda111&quot; for CUDA 11.1+ or &quot;cuda118&quot; for CUDA 11.8</span><span class="w">
  </span><span class="c1"># CUDA 12.x not supported by XLA</span><span class="w">
  </span><span class="c1"># or you can put this value in ENV variables in Livebook settings</span><span class="w">
  </span><span class="c1"># XLA_TARGET=cuda111</span><span class="w">
  </span><span class="c1"># system_env: %{&quot;XLA_TARGET&quot; =&gt; xla_target}</span><span class="w">
</span><span class="p" data-group-id="1634817522-1">)</span></code></pre><h2 id="converting-an-onnx-model-into-axon" class="section-heading">
  <a href="#converting-an-onnx-model-into-axon" class="hover-link">
    <i class="ri-link-m" aria-hidden="true"></i>
  </a>
  <span class="text">Converting an ONNX model into Axon</span>
</h2>
<p>Axon is a new machine learning capability, specific to Elixir. We would like to take
advantage of a large amount of models that have been written in other languages and
machine learning frameworks. Let's take a look at how we could use a model developed
in another language.</p><p>Converting models developed by data scientists into a production capable implementation is a
challenge for all languages and frameworks. <a href="https://onnx.ai/">ONNX</a> is an interchange
format that allows models written in one language or framework to be converted into
another language and framework.</p><p>The source model must use constructs mapped into ONNX. Also, the destination framework must
support the model's ONNX constructs. From an Elixir focus, we are interested in ONNX models
that <a href="https://github.com/elixir-nx/axon_onnx">axon_onnx</a> can convert into Axon models.</p><!-- livebook:{"break_markdown":true} --><h3 id="why-is-onnx-important-to-axon" class="section-heading">
  <a href="#why-is-onnx-important-to-axon" class="hover-link">
    <i class="ri-link-m" aria-hidden="true"></i>
  </a>
  <span class="text">Why is ONNX important to Axon?</span>
</h3>
<!-- livebook:{"break_markdown":true} --><p>Elixir can get access to thousands of public models and your organization may have private models
written in other languages and frameworks. Axon will be hard pressed to quickly repeat the
countless person-hours spent on developing models in other languages like Tensorflow and PyTorch.
However, if the model can be converted into ONNX and then into Axon, we can directly run the model
in Elixir.</p><!-- livebook:{"break_markdown":true} --><h3 id="setting-up-our-environment" class="section-heading">
  <a href="#setting-up-our-environment" class="hover-link">
    <i class="ri-link-m" aria-hidden="true"></i>
  </a>
  <span class="text">Setting up our environment</span>
</h3>
<!-- livebook:{"break_markdown":true} --><p>Axon runs on top of <a href="https://hexdocs.pm/nx">Nx (Numerical Elixir)</a>. Nx has backends for
both Google's XLA (via EXLA) and PyTorch (via Torchx). In this guide, we will use EXLA.
We'll also convert from an ONNX model into an Axon model using
<a href="https://github.com/elixir-nx/axon_onnx"><code class="inline">axon_onnx</code></a>.</p><p>You can find all dependencies in the installation cell at the top of the notebook.
In there, you will also find the <code class="inline">XLA_TARGET</code> environment variable which you can set
to &quot;cuda111&quot; or &quot;rocm&quot; if you have any of those GPUs available. Let's also configure
Nx to store tensors in EXLA by default:</p><pre><code class="makeup elixir" translate="no"><span class="c1">#  Nx.default_backend(EXLA.Backend)</span></code></pre><p>We'll also need local access to ONNX files. For this notebook, the models/onnx folder
contains the ONNX model file. This notebook assumes the output file location will be
in models axon. Copy your ONNX model files into the models/onnx folder.</p><p>This opinionated module presents a simple API for loading in an ONNX file and saving
the converted Axon model in the provided directory. This API will allow us to
save multiple models pretty quickly.</p><pre><code class="makeup elixir" translate="no"><span class="kd">defmodule</span><span class="w"> </span><span class="nc">OnnxToAxon</span><span class="w"> </span><span class="k" data-group-id="5982710744-1">do</span><span class="w">
  </span><span class="na">@moduledoc</span><span class="w"> </span><span class="s">&quot;&quot;&quot;
  Helper module from ONNX to Axon.
  &quot;&quot;&quot;</span><span class="w">

  </span><span class="na">@doc</span><span class="w"> </span><span class="s">&quot;&quot;&quot;
  Loads an ONNX model into Axon and saves the model

  ## Examples

      OnnxToAxon.onnx_axon(path_to_onnx_file, path_to_axon_dir)

  &quot;&quot;&quot;</span><span class="w">
  </span><span class="kd">def</span><span class="w"> </span><span class="nf">onnx_axon</span><span class="p" data-group-id="5982710744-2">(</span><span class="n">path_to_onnx_file</span><span class="p">,</span><span class="w"> </span><span class="n">path_to_axon_dir</span><span class="p" data-group-id="5982710744-2">)</span><span class="w"> </span><span class="k" data-group-id="5982710744-3">do</span><span class="w">
    </span><span class="n">axon_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">axon_name_from_onnx_path</span><span class="p" data-group-id="5982710744-4">(</span><span class="n">path_to_onnx_file</span><span class="p" data-group-id="5982710744-4">)</span><span class="w">
    </span><span class="n">path_to_axon</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Path</span><span class="o">.</span><span class="n">join</span><span class="p" data-group-id="5982710744-5">(</span><span class="n">path_to_axon_dir</span><span class="p">,</span><span class="w"> </span><span class="n">axon_name</span><span class="p" data-group-id="5982710744-5">)</span><span class="w">

    </span><span class="p" data-group-id="5982710744-6">{</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">parameters</span><span class="p" data-group-id="5982710744-6">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">AxonOnnx</span><span class="o">.</span><span class="kn">import</span><span class="p" data-group-id="5982710744-7">(</span><span class="n">path_to_onnx_file</span><span class="p" data-group-id="5982710744-7">)</span><span class="w">
    </span><span class="n">model_bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">serialize</span><span class="p" data-group-id="5982710744-8">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">parameters</span><span class="p" data-group-id="5982710744-8">)</span><span class="w">
    </span><span class="nc">File</span><span class="o">.</span><span class="n">write!</span><span class="p" data-group-id="5982710744-9">(</span><span class="n">path_to_axon</span><span class="p">,</span><span class="w"> </span><span class="n">model_bytes</span><span class="p" data-group-id="5982710744-9">)</span><span class="w">
  </span><span class="k" data-group-id="5982710744-3">end</span><span class="w">

  </span><span class="kd">defp</span><span class="w"> </span><span class="nf">axon_name_from_onnx_path</span><span class="p" data-group-id="5982710744-10">(</span><span class="n">onnx_path</span><span class="p" data-group-id="5982710744-10">)</span><span class="w"> </span><span class="k" data-group-id="5982710744-11">do</span><span class="w">
    </span><span class="n">model_root</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">onnx_path</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Path</span><span class="o">.</span><span class="n">basename</span><span class="p" data-group-id="5982710744-12">(</span><span class="p" data-group-id="5982710744-12">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Path</span><span class="o">.</span><span class="n">rootname</span><span class="p" data-group-id="5982710744-13">(</span><span class="p" data-group-id="5982710744-13">)</span><span class="w">
    </span><span class="s">&quot;</span><span class="si" data-group-id="5982710744-14">#{</span><span class="n">model_root</span><span class="si" data-group-id="5982710744-14">}</span><span class="s">.axon&quot;</span><span class="w">
  </span><span class="k" data-group-id="5982710744-11">end</span><span class="w">
</span><span class="k" data-group-id="5982710744-1">end</span></code></pre><h2 id="onnx-model" class="section-heading">
  <a href="#onnx-model" class="hover-link">
    <i class="ri-link-m" aria-hidden="true"></i>
  </a>
  <span class="text">ONNX model</span>
</h2>
<p>For this example, we'll use a couple ONNX models that have been saved in the Huggingface Hub.</p><!-- livebook:{"break_markdown":true} --><p>The ONNX models were trained in Fast.ai (PyTorch) using the following notebooks:</p><ul><li><a href="https://github.com/meanderingstream/fastai_course22/blob/main/saving-a-basic-fastai-model-in-onnx.ipynb">https://github.com/meanderingstream/fastai_course22/blob/main/saving-a-basic-fastai-model-in-onnx.ipynb</a></li><li><a href="https://github.com/meanderingstream/fastai_course22/blob/main/saving-cat-dog-breed-fastai-model-in-onnx.ipynb">https://github.com/meanderingstream/fastai_course22/blob/main/saving-cat-dog-breed-fastai-model-in-onnx.ipynb</a></li></ul><p>To repeat this notebook, the onnx files for this notebook can be found on huggingface hub. Download the onnx models from:</p><ul><li><a href="https://huggingface.co/ScottMueller/Cats_v_Dogs.ONNX">https://huggingface.co/ScottMueller/Cats_v_Dogs.ONNX</a></li><li><a href="https://huggingface.co/ScottMueller/Cat_Dog_Breeds.ONNX">https://huggingface.co/ScottMueller/Cat_Dog_Breeds.ONNX</a></li></ul><p>Download the files and place them in a directory of your choice. By default, we will assume you downloaded them to the same directory as the notebook:</p><pre><code class="makeup elixir" translate="no"><span class="nc">File</span><span class="o">.</span><span class="n">cd!</span><span class="p" data-group-id="5556007407-1">(</span><span class="bp">__DIR__</span><span class="p" data-group-id="5556007407-1">)</span></code></pre><p>Now let's convert an ONNX model into Axon</p><pre><code class="makeup elixir" translate="no"><span class="n">path_to_onnx_file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;cats_v_dogs.onnx&quot;</span><span class="w">
</span><span class="n">path_to_axon_dir</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;.&quot;</span><span class="w">
</span><span class="nc">OnnxToAxon</span><span class="o">.</span><span class="n">onnx_axon</span><span class="p" data-group-id="4182355222-1">(</span><span class="n">path_to_onnx_file</span><span class="p">,</span><span class="w"> </span><span class="n">path_to_axon_dir</span><span class="p" data-group-id="4182355222-1">)</span></code></pre><pre><code class="makeup elixir" translate="no"><span class="n">path_to_onnx_file</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;cat_dog_breeds.onnx&quot;</span><span class="w">
</span><span class="n">path_to_axon_dir</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;.&quot;</span><span class="w">
</span><span class="nc">OnnxToAxon</span><span class="o">.</span><span class="n">onnx_axon</span><span class="p" data-group-id="1183101601-1">(</span><span class="n">path_to_onnx_file</span><span class="p">,</span><span class="w"> </span><span class="n">path_to_axon_dir</span><span class="p" data-group-id="1183101601-1">)</span></code></pre><h2 id="inference-on-onnx-derived-models" class="section-heading">
  <a href="#inference-on-onnx-derived-models" class="hover-link">
    <i class="ri-link-m" aria-hidden="true"></i>
  </a>
  <span class="text">Inference on ONNX derived models</span>
</h2>
<p>To run inference on the model, you'll need 10 images focused on cats or dogs. You can download the images used in training the model at:</p><p>&quot;<a href="https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz%22">https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz&quot;</a></p><p>Or you can find or use your own images. In this notebook, we are going to use the local copies of the Oxford Pets dataset that was used in training the model.</p><!-- livebook:{"break_markdown":true} --><p>Let's load the Axon model.</p><pre><code class="makeup elixir" translate="no"><span class="n">cats_v_dogs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">File</span><span class="o">.</span><span class="n">read!</span><span class="p" data-group-id="1655575909-1">(</span><span class="s">&quot;cats_v_dogs.axon&quot;</span><span class="p" data-group-id="1655575909-1">)</span><span class="w">
</span><span class="p" data-group-id="1655575909-2">{</span><span class="n">cats_v_dogs_model</span><span class="p">,</span><span class="w"> </span><span class="n">cats_v_dogs_params</span><span class="p" data-group-id="1655575909-2">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">deserialize</span><span class="p" data-group-id="1655575909-3">(</span><span class="n">cats_v_dogs</span><span class="p" data-group-id="1655575909-3">)</span></code></pre><p>We need a tensor representation of an image. Let's start by looking at samples of
our data.</p><pre><code class="makeup elixir" translate="no"><span class="nc">File</span><span class="o">.</span><span class="n">read!</span><span class="p" data-group-id="2086866652-1">(</span><span class="s">&quot;oxford-iiit-pet/images/havanese_71.jpg&quot;</span><span class="p" data-group-id="2086866652-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Kino.Image</span><span class="o">.</span><span class="n">new</span><span class="p" data-group-id="2086866652-2">(</span><span class="ss">:jpeg</span><span class="p" data-group-id="2086866652-2">)</span></code></pre><p>To manipulate the images, we will use the <code class="inline">StbImage</code> library:</p><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="6792517493-1">{</span><span class="ss">:ok</span><span class="p">,</span><span class="w"> </span><span class="n">img</span><span class="p" data-group-id="6792517493-1">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">StbImage</span><span class="o">.</span><span class="n">read_file</span><span class="p" data-group-id="6792517493-2">(</span><span class="s">&quot;oxford-iiit-pet/images/havanese_71.jpg&quot;</span><span class="p" data-group-id="6792517493-2">)</span><span class="w">
</span><span class="p" data-group-id="6792517493-3">%</span><span class="nc" data-group-id="6792517493-3">StbImage</span><span class="p" data-group-id="6792517493-3">{</span><span class="ss">data</span><span class="p">:</span><span class="w"> </span><span class="n">binary</span><span class="p">,</span><span class="w"> </span><span class="ss">shape</span><span class="p">:</span><span class="w"> </span><span class="n">shape</span><span class="p">,</span><span class="w"> </span><span class="ss">type</span><span class="p">:</span><span class="w"> </span><span class="n">type</span><span class="p" data-group-id="6792517493-3">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">StbImage</span><span class="o">.</span><span class="n">resize</span><span class="p" data-group-id="6792517493-4">(</span><span class="n">img</span><span class="p">,</span><span class="w"> </span><span class="mi">224</span><span class="p">,</span><span class="w"> </span><span class="mi">224</span><span class="p" data-group-id="6792517493-4">)</span></code></pre><p>Now let's work on a batch of images and convert them to tensors. Here are the images we will work with:</p><pre><code class="makeup elixir" translate="no"><span class="n">file_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="1103422284-1">[</span><span class="w">
  </span><span class="s">&quot;havanese_71.jpg&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;yorkshire_terrier_9.jpg&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;Sphynx_206.jpg&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;Siamese_95.jpg&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;Egyptian_Mau_63.jpg&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;keeshond_175.jpg&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;samoyed_88.jpg&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;British_Shorthair_122.jpg&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;Russian_Blue_20.jpg&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;boxer_99.jpg&quot;</span><span class="w">
</span><span class="p" data-group-id="1103422284-1">]</span></code></pre><p>Next we resize the images:</p><pre><code class="makeup elixir" translate="no"><span class="n">resized_images</span><span class="w"> </span><span class="o">=</span><span class="w">
  </span><span class="nc">Enum</span><span class="o">.</span><span class="n">map</span><span class="p" data-group-id="8555162000-1">(</span><span class="n">file_names</span><span class="p">,</span><span class="w"> </span><span class="k" data-group-id="8555162000-2">fn</span><span class="w"> </span><span class="n">file_name</span><span class="w"> </span><span class="o">-&gt;</span><span class="w">
    </span><span class="p" data-group-id="8555162000-3">(</span><span class="s">&quot;oxford-iiit-pet/images/&quot;</span><span class="w"> </span><span class="o">&lt;&gt;</span><span class="w"> </span><span class="n">file_name</span><span class="p" data-group-id="8555162000-3">)</span><span class="w">
    </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">IO</span><span class="o">.</span><span class="n">inspect</span><span class="p" data-group-id="8555162000-4">(</span><span class="ss">label</span><span class="p">:</span><span class="w"> </span><span class="n">file_name</span><span class="p" data-group-id="8555162000-4">)</span><span class="w">
    </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">StbImage</span><span class="o">.</span><span class="n">read_file!</span><span class="p" data-group-id="8555162000-5">(</span><span class="p" data-group-id="8555162000-5">)</span><span class="w">
    </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">StbImage</span><span class="o">.</span><span class="n">resize</span><span class="p" data-group-id="8555162000-6">(</span><span class="mi">224</span><span class="p">,</span><span class="w"> </span><span class="mi">224</span><span class="p" data-group-id="8555162000-6">)</span><span class="w">
  </span><span class="k" data-group-id="8555162000-2">end</span><span class="p" data-group-id="8555162000-1">)</span></code></pre><p>And finally convert them into tensors by using <code class="inline">StbImage.to_nx/1</code>. The created tensor will have three axes, named <code class="inline">:height</code>, <code class="inline">:width</code>, and <code class="inline">:channel</code> respectively. Our goal is to stack the tensors, then normalize and transpose their axes to the order expected by the neural network:</p><pre><code class="makeup elixir" translate="no"><span class="n">img_tensors</span><span class="w"> </span><span class="o">=</span><span class="w">
  </span><span class="n">resized_images</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Enum</span><span class="o">.</span><span class="n">map</span><span class="p" data-group-id="6227107304-1">(</span><span class="o">&amp;</span><span class="nc">StbImage</span><span class="o">.</span><span class="n">to_nx</span><span class="o">/</span><span class="mi">1</span><span class="p" data-group-id="6227107304-1">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">stack</span><span class="p" data-group-id="6227107304-2">(</span><span class="ss">name</span><span class="p">:</span><span class="w"> </span><span class="ss">:index</span><span class="p" data-group-id="6227107304-2">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">divide</span><span class="p" data-group-id="6227107304-3">(</span><span class="mf">255.0</span><span class="p" data-group-id="6227107304-3">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">transpose</span><span class="p" data-group-id="6227107304-4">(</span><span class="ss">axes</span><span class="p">:</span><span class="w"> </span><span class="p" data-group-id="6227107304-5">[</span><span class="ss">:index</span><span class="p">,</span><span class="w"> </span><span class="ss">:channels</span><span class="p">,</span><span class="w"> </span><span class="ss">:height</span><span class="p">,</span><span class="w"> </span><span class="ss">:width</span><span class="p" data-group-id="6227107304-5">]</span><span class="p" data-group-id="6227107304-4">)</span></code></pre><p>With our input data, it is finally time to work on predictions. First let's define a helper module:</p><pre><code class="makeup elixir" translate="no"><span class="kd">defmodule</span><span class="w"> </span><span class="nc">Predictions</span><span class="w"> </span><span class="k" data-group-id="2645831795-1">do</span><span class="w">
  </span><span class="na">@doc</span><span class="w"> </span><span class="s">&quot;&quot;&quot;
  When provided a Tensor of single label predictions, returns the best vocabulary match for
  each row in the prediction tensor.

  ## Examples

     # iex&gt; Predictions.sindle_label_prediction(path_to_onnx_file, path_to_axon_dir)
     # [&quot;dog&quot;, &quot;cat&quot;, &quot;dog&quot;]

  &quot;&quot;&quot;</span><span class="w">
  </span><span class="kd">def</span><span class="w"> </span><span class="nf">single_label_classification</span><span class="p" data-group-id="2645831795-2">(</span><span class="n">predictions_batch</span><span class="p">,</span><span class="w"> </span><span class="n">vocabulary</span><span class="p" data-group-id="2645831795-2">)</span><span class="w"> </span><span class="k" data-group-id="2645831795-3">do</span><span class="w">
    </span><span class="nc">IO</span><span class="o">.</span><span class="n">inspect</span><span class="p" data-group-id="2645831795-4">(</span><span class="nc">Nx</span><span class="o">.</span><span class="n">shape</span><span class="p" data-group-id="2645831795-5">(</span><span class="n">predictions_batch</span><span class="p" data-group-id="2645831795-5">)</span><span class="p">,</span><span class="w"> </span><span class="ss">label</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;predictions batch shape&quot;</span><span class="p" data-group-id="2645831795-4">)</span><span class="w">

    </span><span class="k">for</span><span class="w"> </span><span class="n">prediction_tensor</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">to_batched</span><span class="p" data-group-id="2645831795-6">(</span><span class="n">predictions_batch</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p" data-group-id="2645831795-6">)</span><span class="w"> </span><span class="k" data-group-id="2645831795-7">do</span><span class="w">
      </span><span class="p" data-group-id="2645831795-8">{</span><span class="c">_prediction_value</span><span class="p">,</span><span class="w"> </span><span class="n">prediction_label</span><span class="p" data-group-id="2645831795-8">}</span><span class="w"> </span><span class="o">=</span><span class="w">
        </span><span class="n">prediction_tensor</span><span class="w">
        </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">to_flat_list</span><span class="p" data-group-id="2645831795-9">(</span><span class="p" data-group-id="2645831795-9">)</span><span class="w">
        </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Enum</span><span class="o">.</span><span class="n">zip</span><span class="p" data-group-id="2645831795-10">(</span><span class="n">vocabulary</span><span class="p" data-group-id="2645831795-10">)</span><span class="w">
        </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Enum</span><span class="o">.</span><span class="n">max</span><span class="p" data-group-id="2645831795-11">(</span><span class="p" data-group-id="2645831795-11">)</span><span class="w">

      </span><span class="n">prediction_label</span><span class="w">
    </span><span class="k" data-group-id="2645831795-7">end</span><span class="w">
  </span><span class="k" data-group-id="2645831795-3">end</span><span class="w">
</span><span class="k" data-group-id="2645831795-1">end</span></code></pre><p>Now we deserialize the model</p><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="5317559793-1">{</span><span class="n">cats_v_dogs_model</span><span class="p">,</span><span class="w"> </span><span class="n">cats_v_dogs_params</span><span class="p" data-group-id="5317559793-1">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">deserialize</span><span class="p" data-group-id="5317559793-2">(</span><span class="n">cats_v_dogs</span><span class="p" data-group-id="5317559793-2">)</span></code></pre><p>run a prediction using the <code class="inline">EXLA</code> compiler for performance</p><pre><code class="makeup elixir" translate="no"><span class="n">tensor_of_predictions</span><span class="w"> </span><span class="o">=</span><span class="w">
  </span><span class="nc">Axon</span><span class="o">.</span><span class="n">predict</span><span class="p" data-group-id="9507053153-1">(</span><span class="n">cats_v_dogs_model</span><span class="p">,</span><span class="w"> </span><span class="n">cats_v_dogs_params</span><span class="p">,</span><span class="w"> </span><span class="n">img_tensors</span><span class="p">,</span><span class="w"> </span><span class="ss">compiler</span><span class="p">:</span><span class="w"> </span><span class="nc">EXLA</span><span class="p" data-group-id="9507053153-1">)</span></code></pre><p>and finally retrieve the predicted label</p><pre><code class="makeup elixir" translate="no"><span class="n">dog_cat_vocabulary</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="0095770874-1">[</span><span class="w">
  </span><span class="s">&quot;dog&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;cat&quot;</span><span class="w">
</span><span class="p" data-group-id="0095770874-1">]</span><span class="w">

</span><span class="nc">Predictions</span><span class="o">.</span><span class="n">single_label_classification</span><span class="p" data-group-id="0095770874-2">(</span><span class="n">tensor_of_predictions</span><span class="p">,</span><span class="w"> </span><span class="n">dog_cat_vocabulary</span><span class="p" data-group-id="0095770874-2">)</span></code></pre><p>Let's repeat the above process for the dog and cat breed model.</p><pre><code class="makeup elixir" translate="no"><span class="n">cat_dog_vocabulary</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p" data-group-id="6723092890-1">[</span><span class="w">
  </span><span class="s">&quot;abyssinian&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;american_bulldog&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;american_pit_bull_terrier&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;basset_hound&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;beagle&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;bengal&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;birman&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;bombay&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;boxer&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;british_shorthair&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;chihuahua&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;egyptian_mau&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;english_cocker_spaniel&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;english_setter&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;german_shorthaired&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;great_pyrenees&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;havanese&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;japanese_chin&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;keeshond&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;leonberger&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;maine_coon&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;miniature_pinscher&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;newfoundland&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;persian&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;pomeranian&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;pug&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;ragdoll&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;russian_blue&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;saint_bernard&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;samoyed&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;scottish_terrier&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;shiba_inu&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;siamese&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;sphynx&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;staffordshire_bull_terrier&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;wheaten_terrier&quot;</span><span class="p">,</span><span class="w">
  </span><span class="s">&quot;yorkshire_terrier&quot;</span><span class="w">
</span><span class="p" data-group-id="6723092890-1">]</span></code></pre><pre><code class="makeup elixir" translate="no"><span class="n">cat_dog_breeds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">File</span><span class="o">.</span><span class="n">read!</span><span class="p" data-group-id="9633866762-1">(</span><span class="s">&quot;cat_dog_breeds.axon&quot;</span><span class="p" data-group-id="9633866762-1">)</span><span class="w">
</span><span class="p" data-group-id="9633866762-2">{</span><span class="n">cat_dog_breeds_model</span><span class="p">,</span><span class="w"> </span><span class="n">cat_dog_breeds_params</span><span class="p" data-group-id="9633866762-2">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Axon</span><span class="o">.</span><span class="n">deserialize</span><span class="p" data-group-id="9633866762-3">(</span><span class="n">cat_dog_breeds</span><span class="p" data-group-id="9633866762-3">)</span></code></pre><pre><code class="makeup elixir" translate="no"><span class="nc">Axon</span><span class="o">.</span><span class="n">predict</span><span class="p" data-group-id="6252307840-1">(</span><span class="n">cat_dog_breeds_model</span><span class="p">,</span><span class="w"> </span><span class="n">cat_dog_breeds_params</span><span class="p">,</span><span class="w"> </span><span class="n">img_tensors</span><span class="p" data-group-id="6252307840-1">)</span><span class="w">
</span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Predictions</span><span class="o">.</span><span class="n">single_label_classification</span><span class="p" data-group-id="6252307840-2">(</span><span class="n">cat_dog_vocabulary</span><span class="p" data-group-id="6252307840-2">)</span></code></pre><p>For cat and dog breeds, the model performed pretty well, but it was not perfect.</p>
<div class="bottom-actions">
  <div class="bottom-actions-item">

      <a href="writing_custom_event_handlers.html" class="bottom-actions-button" rel="prev">
        <span class="subheader">
          ← Previous Page
        </span>
        <span class="title">
Writing custom event handlers
        </span>
      </a>

  </div>
  <div class="bottom-actions-item">

      <a href="xor.html" class="bottom-actions-button" rel="next">
        <span class="subheader">
          Next Page →
        </span>
        <span class="title">
Modeling XOR with a neural network
        </span>
      </a>

  </div>
</div>
      <footer class="footer">
        <p>

            <span class="line">
              <a href="https://hex.pm/packages/axon/0.6.1" class="footer-hex-package">Hex Package</a>

              <a href="https://preview.hex.pm/preview/axon/0.6.1">Hex Preview</a>

                (<a href="https://preview.hex.pm/preview/axon/0.6.1/show/guides/serialization/onnx_to_axon.livemd">current file</a>)

            </span>

          <span class="line">
            <button class="a-main footer-button display-quick-switch" title="Search HexDocs packages">
              Search HexDocs
            </button>

              <a href="Axon.epub" title="ePub version">
                Download ePub version
              </a>

          </span>
        </p>

        <p class="built-using">
          Built using
          <a href="https://github.com/elixir-lang/ex_doc" title="ExDoc" target="_blank" rel="help noopener" translate="no">ExDoc</a> (v0.31.1) for the

            <a href="https://elixir-lang.org" title="Elixir" target="_blank" translate="no">Elixir programming language</a>

        </p>
      </footer>
    </div>
  </div>
</main>
</div>

<!-- Render math with KaTeX -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css" integrity="sha384-t5CR+zwDAROtph0PXGte6ia8heboACF9R5l/DiY+WZ3P2lxNgvJkQk5n7GPvLMYw" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js" integrity="sha384-FaFLTlohFghEIZkw6VGwmf9ISTubWAVYW8tG8+w2LAIftJEULZABrF9PPFv+tVkH" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js" integrity="sha384-bHBqxz8fokvgoJ/sc17HODNxa42TlaEhB+w8ZJXTc2nZf1VgEaFZeZvT4Mznfz0v" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
      ]
    });
  });
</script>

<!-- Render diagrams with Mermaid -->
<script src="https://cdn.jsdelivr.net/npm/mermaid@8.13.3/dist/mermaid.min.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    mermaid.initialize({ startOnLoad: false });
    let id = 0;
    for (const codeEl of document.querySelectorAll("pre code.mermaid")) {
      const preEl = codeEl.parentElement;
      const graphDefinition = codeEl.textContent;
      const graphEl = document.createElement("div");
      const graphId = "mermaid-graph-" + id++;
      mermaid.render(graphId, graphDefinition, function (svgSource, bindListeners) {
        graphEl.innerHTML = svgSource;
        bindListeners && bindListeners(graphEl);
        preEl.insertAdjacentElement("afterend", graphEl);
        preEl.remove();
      });
    }
  });
</script>

  </body>
</html>
